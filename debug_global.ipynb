{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script for FCNT tracker. \n",
    "\"\"\"\n",
    "#%%\n",
    "# Import custom class and functions\n",
    "from inputproducer import InputProducer\n",
    "from tracker import TrackerVanilla\n",
    "from vgg16 import Vgg16\n",
    "from selcnn import SelCNN\n",
    "from sgnet import GNet, SNet\n",
    "from utils import img_with_bbox, IOU_eval\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "#%%\n",
    "tf.app.flags.DEFINE_integer('iter_step_sel', 200,\n",
    "                          \"\"\"Number of steps for trainning\"\"\"\n",
    "                          \"\"\"selCNN networks.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('iter_step_sg', 50,\n",
    "                          \"\"\"Number of steps for trainning\"\"\"\n",
    "                          \"\"\"SGnet works\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_sel', 384,\n",
    "                          \"\"\"Number of feature maps selected.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('iter_max', 200,\n",
    "\t\t\t\t\t\t\t\"\"\"Max iter times through imgs\"\"\")\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "## Define varies path\n",
    "DATA_ROOT = 'data/Dog1'\n",
    "IMG_PATH = os.path.join(DATA_ROOT, 'img')\n",
    "GT_PATH = os.path.join(DATA_ROOT, 'groundtruth_rect.txt')\n",
    "VGG_WEIGHTS_PATH = 'vgg16_weights.npz'\n",
    "#%%\n",
    "def train_selCNN(sess, selCNN, feed_dict):\n",
    "\t# Initialize variables\n",
    "\tglobal_step = tf.Variable(0, trainable=False)\n",
    "\tselCNN_vars = selCNN.variables \n",
    "\tinit_vars_op = tf.initialize_variables(selCNN_vars + [global_step], name='init_selCNN')\n",
    "\tsess.run(init_vars_op)\n",
    "\n",
    "\t# Retrive trainning op\n",
    "\ttrain_op, losses, lr, optimizer = selCNN.train_op(global_step)\n",
    "\tprint(sess.run(tf.report_uninitialized_variables()))\n",
    "\t# Train for iter_step_sel times\n",
    "\t# Inspects loss curve and pre_M visually\n",
    "\tfor step in range(FLAGS.iter_step_sel):\n",
    "\t\t_, total_loss, lr_ = sess.run([train_op, losses, lr], feed_dict=feed_dict)\n",
    "\t\tprint(total_loss)\n",
    "\n",
    "\n",
    "def train_sgNet(sess, gnet, snet, sgt_M, ggt_M, feed_dict):\n",
    "\t\"\"\"\n",
    "\tTrain sgnet by minimize the loss\n",
    "\tLoss = Lg + Ls\n",
    "\twhere Li = |pre_Mi - gt_M|**2 + Weights_decay_term_i\n",
    "\n",
    "\t\"\"\"\n",
    "\t# Initialize sgNet variables\n",
    "\tsgNet_vars = gnet.variables + snet.variables\n",
    "\tinit_SGNet_vars_op = tf.initialize_variables(sgNet_vars, name='init_sgNet')\n",
    "\tsess.run(init_SGNet_vars_op)\n",
    "\n",
    "\t# Define composite loss\n",
    "\ttotal_losses = snet.loss(sgt_M) + gnet.loss(ggt_M)\n",
    "\n",
    "\t# Define trainning op\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(1e-6)\n",
    "\ttrain_op = optimizer.minimize(total_losses, var_list= sgNet_vars)\n",
    "\n",
    "\tfor step in range(FLAGS.iter_step_sg):\n",
    "\t\tloss, _ = sess.run([total_losses, train_op], feed_dict = feed_dict)\n",
    "\t\tprint(loss)\n",
    "\n",
    "\n",
    "\n",
    "def gen_mask_phi(img_sz, loc):\n",
    "\tx,y,w,h = loc\n",
    "\tphi = np.zeros(img_sz)\n",
    "\tphi[y-int(0.5*h): y+int(0.5*h), x-int(0.5*w):x+int(0.5*w)] = 1\n",
    "\treturn phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xlws/repos/FCNT_TF/inputproducer.py:85: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  roi = convas[cy-half:cy+half, cx-half:cx+half, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old English sheepdog, bobtail 0.654105\n",
      "miniature poodle 0.0409054\n",
      "Tibetan terrier, chrysanthemum dog 0.0321338\n",
      "standard poodle 0.0294567\n",
      "Sealyham terrier, Sealyham 0.0269377\n",
      "0.0013186425201 max of mask\n",
      "(224, 224, 3)\n",
      "250 max convas\n",
      "[]\n",
      "6.24955\n",
      "6.72138\n",
      "6.84566\n",
      "6.60599\n",
      "6.74102\n",
      "6.42663\n",
      "6.34022\n",
      "6.57497\n",
      "6.68752\n",
      "6.69023\n",
      "6.87499\n",
      "6.88316\n",
      "6.51023\n",
      "6.44164\n",
      "6.3163\n",
      "6.40377\n",
      "6.6733\n",
      "6.59548\n",
      "7.39637\n",
      "6.76343\n",
      "6.63283\n",
      "6.97001\n",
      "6.49342\n",
      "6.79834\n",
      "6.84682\n",
      "6.7791\n",
      "6.69084\n",
      "6.76442\n",
      "6.40401\n",
      "6.31935\n",
      "6.41752\n",
      "6.42161\n",
      "6.32999\n",
      "6.82438\n",
      "6.30624\n",
      "6.81193\n",
      "6.32685\n",
      "6.93009\n",
      "7.05138\n",
      "6.58546\n",
      "6.51173\n",
      "6.3929\n",
      "6.93226\n",
      "6.55511\n",
      "6.64598\n",
      "6.2998\n",
      "6.932\n",
      "6.49809\n",
      "6.76801\n",
      "7.0186\n",
      "6.71637\n",
      "6.58757\n",
      "6.64891\n",
      "6.71199\n",
      "6.58561\n",
      "6.65325\n",
      "6.5383\n",
      "6.88126\n",
      "6.76699\n",
      "6.15861\n",
      "6.39608\n",
      "6.78094\n",
      "6.7321\n",
      "6.64148\n",
      "6.62454\n",
      "6.55969\n",
      "6.9972\n",
      "6.93911\n",
      "6.52063\n",
      "6.63478\n",
      "6.8553\n",
      "6.4667\n",
      "6.68106\n",
      "6.83305\n",
      "6.86904\n",
      "6.82761\n",
      "6.87282\n",
      "7.08774\n",
      "7.00538\n",
      "7.14762\n",
      "6.87149\n",
      "6.31789\n",
      "6.59749\n",
      "6.66101\n",
      "6.98662\n",
      "6.64763\n",
      "6.21712\n",
      "6.58686\n",
      "6.63439\n",
      "7.0363\n",
      "7.16503\n",
      "6.65444\n",
      "6.61598\n",
      "6.42774\n",
      "6.88458\n",
      "6.75254\n",
      "6.44872\n",
      "6.31491\n",
      "6.82819\n",
      "6.98228\n",
      "6.54184\n",
      "6.69878\n",
      "6.47439\n",
      "6.49496\n",
      "6.65444\n",
      "6.82837\n",
      "6.67639\n",
      "6.35862\n",
      "6.76666\n",
      "6.60461\n",
      "6.60721\n",
      "6.74169\n",
      "6.6936\n",
      "6.69023\n",
      "6.86729\n",
      "6.41353\n",
      "6.72759\n",
      "6.529\n",
      "6.41624\n",
      "6.82552\n",
      "6.56119\n",
      "6.62268\n",
      "6.91209\n",
      "6.41852\n",
      "6.90574\n",
      "6.39872\n",
      "6.6299\n",
      "6.39313\n",
      "6.5243\n",
      "6.79328\n",
      "6.6509\n",
      "6.27008\n",
      "6.48363\n",
      "6.34213\n",
      "6.95248\n",
      "6.58816\n",
      "6.90876\n",
      "6.54788\n",
      "6.88584\n",
      "6.66143\n",
      "6.49384\n",
      "6.55722\n",
      "6.84529\n",
      "6.60942\n",
      "6.79665\n",
      "6.73536\n",
      "6.36463\n",
      "7.00413\n",
      "6.80116\n",
      "6.81245\n",
      "6.66587\n",
      "6.49638\n",
      "6.74752\n",
      "6.99793\n",
      "6.81842\n",
      "6.80328\n",
      "6.26004\n",
      "6.96885\n",
      "6.43157\n",
      "6.6921\n",
      "6.7501\n",
      "6.53252\n",
      "6.78342\n",
      "6.28573\n",
      "6.70558\n",
      "6.70628\n",
      "6.48944\n",
      "6.57384\n",
      "6.83737\n",
      "6.57455\n",
      "6.50061\n",
      "6.60932\n",
      "6.69355\n",
      "6.4957\n",
      "6.80368\n",
      "6.85462\n",
      "6.23654\n",
      "6.49854\n",
      "6.67271\n",
      "6.48587\n",
      "6.84304\n",
      "6.41626\n",
      "6.71599\n",
      "6.66762\n",
      "6.54649\n",
      "6.68436\n",
      "6.31851\n",
      "6.71265\n",
      "6.80573\n",
      "6.7203\n",
      "6.90822\n",
      "6.65446\n",
      "6.55544\n",
      "6.84894\n",
      "6.70014\n",
      "6.71871\n",
      "6.48715\n",
      "6.45921\n",
      "6.57745\n",
      "6.31504\n"
     ]
    }
   ],
   "source": [
    "## Instantiate inputProducer and retrive the first img\n",
    "# with associated ground truth. \n",
    "inputProducer = InputProducer(IMG_PATH, GT_PATH)\n",
    "img, gt, t  = next(inputProducer.gen_img)\n",
    "roi_t0, _, _ = inputProducer.extract_roi(img, gt)\n",
    "\n",
    "# Predicts the first img.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "vgg = Vgg16(VGG_WEIGHTS_PATH, sess)\n",
    "vgg.print_prob(roi_t0, sess)\n",
    "\n",
    "\n",
    "lselCNN = SelCNN('sel_local', vgg.conv4_3, (1,28,28,1))\n",
    "sgt_M = inputProducer.gen_mask(lselCNN.pre_M_size)\n",
    "sgt_M = sgt_M[np.newaxis,:,:,np.newaxis]\n",
    "feed_dict = {vgg.imgs: [roi_t0], lselCNN.gt_M: sgt_M}\n",
    "train_selCNN(sess, lselCNN, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013186425201 max of mask\n",
      "(224, 224, 3)\n",
      "228 max convas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xlws/repos/FCNT_TF/inputproducer.py:85: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  roi = convas[cy-half:cy+half, cx-half:cx+half, :]\n"
     ]
    }
   ],
   "source": [
    "gselCNN = SelCNN('sel_global', vgg.conv5_3, (1,14,14,1))\n",
    "\n",
    "# Gen anotated mask for target arear\n",
    "ggt_M = inputProducer.gen_mask(gselCNN.pre_M_size)\n",
    "\n",
    "## Train selCNN networks with first frame roi\n",
    "# reshape gt_M for compatabilities\n",
    "\n",
    "ggt_M = ggt_M[np.newaxis,:,:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "7.45898\n",
      "7.18705\n",
      "7.60542\n",
      "7.22822\n",
      "7.17818\n",
      "7.13465\n",
      "7.53609\n",
      "7.20013\n",
      "7.74993\n",
      "7.42395\n",
      "7.65614\n",
      "7.4669\n",
      "7.23219\n",
      "7.30863\n",
      "7.45034\n",
      "7.55876\n",
      "7.20524\n",
      "7.69552\n",
      "7.02159\n",
      "7.47021\n",
      "7.21452\n",
      "7.19345\n",
      "6.99465\n",
      "7.10267\n",
      "7.026\n",
      "7.29146\n",
      "7.46323\n",
      "7.45864\n",
      "7.43257\n",
      "6.95836\n",
      "7.37717\n",
      "7.32549\n",
      "7.03209\n",
      "7.0665\n",
      "7.19673\n",
      "7.28802\n",
      "6.76567\n",
      "7.1914\n",
      "7.2316\n",
      "7.17945\n",
      "7.57196\n",
      "7.41841\n",
      "7.24527\n",
      "7.25672\n",
      "7.23772\n",
      "7.38088\n",
      "7.47429\n",
      "7.323\n",
      "7.39932\n",
      "7.05511\n",
      "7.38201\n",
      "7.034\n",
      "7.63812\n",
      "7.03099\n",
      "7.19835\n",
      "6.9884\n",
      "7.41543\n",
      "7.44386\n",
      "6.88429\n",
      "6.79032\n",
      "7.85837\n",
      "7.15966\n",
      "7.6223\n",
      "6.97199\n",
      "7.13589\n",
      "7.35873\n",
      "7.22758\n",
      "6.82742\n",
      "7.11123\n",
      "7.57246\n",
      "7.29468\n",
      "7.82809\n",
      "7.07535\n",
      "7.39229\n",
      "7.00296\n",
      "7.14005\n",
      "6.76448\n",
      "7.39539\n",
      "7.37311\n",
      "7.40585\n",
      "7.93474\n",
      "7.21463\n",
      "7.23193\n",
      "7.03047\n",
      "7.43868\n",
      "7.02994\n",
      "7.63209\n",
      "7.5435\n",
      "7.26362\n",
      "7.43913\n",
      "7.23781\n",
      "7.59292\n",
      "7.43953\n",
      "7.70063\n",
      "7.30031\n",
      "7.51797\n",
      "7.48542\n",
      "7.0717\n",
      "7.6034\n",
      "6.94664\n",
      "7.52211\n",
      "7.03897\n",
      "7.27644\n",
      "7.12308\n",
      "7.60911\n",
      "7.37688\n",
      "7.61241\n",
      "7.00234\n",
      "7.57979\n",
      "7.00004\n",
      "6.97601\n",
      "7.07745\n",
      "7.11427\n",
      "7.17251\n",
      "7.5678\n",
      "7.35608\n",
      "7.47322\n",
      "7.46241\n",
      "7.28779\n",
      "7.35634\n",
      "7.31761\n",
      "7.20186\n",
      "7.25613\n",
      "7.2778\n",
      "7.79274\n",
      "7.42668\n",
      "7.6797\n",
      "7.1817\n",
      "7.76345\n",
      "7.60241\n",
      "7.53932\n",
      "7.45159\n",
      "6.92615\n",
      "6.99716\n",
      "7.44864\n",
      "7.22895\n",
      "7.22556\n",
      "7.25115\n",
      "7.52614\n",
      "6.80454\n",
      "7.70068\n",
      "7.00858\n",
      "7.41188\n",
      "7.79873\n",
      "7.00566\n",
      "7.55876\n",
      "7.64381\n",
      "7.48897\n",
      "6.7978\n",
      "6.93778\n",
      "7.39416\n",
      "7.23173\n",
      "7.10613\n",
      "7.42097\n",
      "7.20086\n",
      "7.68646\n",
      "7.4152\n",
      "7.41155\n",
      "7.67237\n",
      "7.05636\n",
      "7.59512\n",
      "7.32066\n",
      "7.4552\n",
      "7.30091\n",
      "7.44166\n",
      "7.52845\n",
      "7.72356\n",
      "7.19703\n",
      "7.19764\n",
      "7.55621\n",
      "7.37662\n",
      "7.34897\n",
      "7.59383\n",
      "7.17764\n",
      "7.75266\n",
      "7.2609\n",
      "6.96489\n",
      "7.42752\n",
      "7.27466\n",
      "7.54683\n",
      "7.1028\n",
      "7.28352\n",
      "7.0433\n",
      "7.10727\n",
      "7.50731\n",
      "7.35455\n",
      "7.42343\n",
      "7.19856\n",
      "7.39586\n",
      "7.18202\n",
      "7.01689\n",
      "7.20856\n",
      "7.51875\n",
      "7.41501\n",
      "7.51972\n",
      "7.3729\n",
      "7.38563\n",
      "7.14517\n",
      "7.02744\n",
      "7.58507\n"
     ]
    }
   ],
   "source": [
    "feed_dict[gselCNN.gt_M] = ggt_M # corrpus the other nets?\n",
    "\n",
    "train_selCNN(sess, gselCNN, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sel part debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads = tf.gradients(lselCNN.loss, lselCNN.feature_maps)\n",
    "H_diag = [tf.gradients(grads[i], lselCNN.feature_maps[i])[0] for i in range(512)]\n",
    "S = [tf.reduce_sum(-tf.mul(grads[i], lselCNN.feature_maps[i])) \\\n",
    "    + 0.5 * tf.reduce_sum(tf.mul(H_diag[i], lselCNN.feature_maps[i]**2)) for i in range(512)]\n",
    "S_tensor = tf.pack(S, axis=0) # shape (512,)\n",
    "vgg_maps, signif_v = sess.run([vgg.conv4_3, S_tensor], feed_dict=feed_dict)\n",
    "idxs = sorted(range(len(signif_v)), key=lambda i: signif_v[i])[-FLAGS.num_sel:]\n",
    "best_maps = vgg_maps[...,idxs]\n",
    "print('Selected maps shape: {0}'.format(best_maps.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_sel_maps, s_idx = best_maps, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected maps shape: (1, 14, 14, 384)\n"
     ]
    }
   ],
   "source": [
    "grads = tf.gradients(gselCNN.loss, gselCNN.feature_maps)\n",
    "H_diag = [tf.gradients(grads[i], gselCNN.feature_maps[i])[0] for i in range(512)]\n",
    "S = [tf.reduce_sum(-tf.mul(grads[i], gselCNN.feature_maps[i])) \\\n",
    "    + 0.5 * tf.reduce_sum(tf.mul(H_diag[i], gselCNN.feature_maps[i]**2)) for i in range(512)]\n",
    "S_tensor = tf.pack(S, axis=0) # shape (512,)\n",
    "vgg_maps, signif_v = sess.run([vgg.conv5_3, S_tensor], feed_dict=feed_dict)\n",
    "idxs = sorted(range(len(signif_v)), key=lambda i: signif_v[i])[-FLAGS.num_sel:]\n",
    "best_maps = vgg_maps[...,idxs]\n",
    "print('Selected maps shape: {0}'.format(best_maps.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_sel_maps, g_idx = best_maps, idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug sgnet initializae "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sgnet import SGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from utils import variable_on_cpu, variable_with_weight_decay\n",
    "\n",
    "\n",
    "\n",
    "class SGNet:\n",
    "\t# Define class level optimizer\n",
    "\tlr = 1e-6\n",
    "\t#optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "\tdef __init__(self, scope, vgg_conv_shape):\n",
    "\t\t\"\"\"\n",
    "\t\tBase calss for SGNet, defines the network structure\n",
    "\t\t\"\"\"\n",
    "\t\ttracker.scope = scope\n",
    "\t\ttracker.params = {\n",
    "\t\t'num_fms': 200, # number of selected featrue maps, inputs of the network\n",
    "\t\t'wd': 0.5, # L2 regulization coefficient\n",
    "\t\t}\n",
    "\t\ttracker.variables = []\n",
    "\t\twith tf.variable_scope(scope) as scope:\n",
    "\t\t\ttracker.pre_M = tracker._build_graph(vgg_conv_shape)\n",
    "\n",
    "\tdef _build_graph(self, vgg_conv_shape):\n",
    "\t\t\"\"\"\n",
    "\t\tDefine Structure. \n",
    "\t\tThe first additional convolutional\n",
    "\t\tlayer has convolutional kernels of size 9×9 and outputs\n",
    "\t\t36 feature maps as the input to the next layer. The second\n",
    "\t\tadditional convolutional layer has kernels of size 5 × 5\n",
    "\t\tand outputs the foreground heat map of the input image.\n",
    "\t\tReLU is chosen as the nonlinearity for these two layers.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t    vgg_conv_shape: \n",
    "\t\tReturns:\n",
    "\t\t    conv2: \n",
    "\t\t\"\"\"\n",
    "\t\ttracker.variables = []\n",
    "\t\ttracker.kernel_weights = []\n",
    "\t\tout_num = vgg_conv_shape[-1]\n",
    "\n",
    "\t\ttracker.input_maps = tf.placeholder(tf.float32, shape=vgg_conv_shape,\n",
    "\t\t    name='selected_maps')\n",
    "\t\t#assert vgg_conv_shape[-1] == tracker.params['num_fms']\n",
    "        \n",
    "\t\twith tf.name_scope('conv1') as scope:\n",
    "\t\t\tkernel = tf.Variable(tf.truncated_normal([9,9,out_num,36],         dtype=tf.float32,stddev=1e-1), name='weights')\n",
    "\n",
    "\t\t\tconv = tf.nn.conv2d(tracker.input_maps, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[36], dtype=tf.float32),trainable=True, name='biases')\n",
    "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
    "\t\t\tconv1 = tf.nn.relu(out, name=scope)\n",
    "\t\t\ttracker.variables += [kernel, biases]\n",
    "\t\t\ttracker.kernel_weights += [kernel]\n",
    "\t\t\tprint(conv1.get_shape().as_list(), 'conv1 shape')\n",
    "\n",
    "\n",
    "\t\twith tf.name_scope('conv2') as scope:\n",
    "\t\t\tkernel = tf.Variable(tf.truncated_normal([5,5,36,1], dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "\t\t\tconv = tf.nn.conv2d(conv1, kernel , [1, 1, 1, 1], padding='SAME')\n",
    "\t\t\tprint(conv.get_shape().as_list(), 'conv shape')\n",
    "\t\t\tbiases = tf.Variable(tf.constant(0.0, shape=[1], dtype=tf.float32),\n",
    "\t\t\t                     trainable=True, name='biases')\n",
    "\t\t\tout = tf.nn.bias_add(conv, biases)\n",
    "\t\t\tconv2 = tf.nn.relu(out, name=scope)\n",
    "\t\t\ttracker.variables += [kernel, biases]\n",
    "\t\t\ttracker.kernel_weights += [kernel]\n",
    "\n",
    "\t\tprint('Shape of the out put heat map for %s is %s'%(tracker.scope, conv2.get_shape().as_list()))\n",
    "\t\treturn conv2\n",
    "\n",
    "\tdef loss(self, gt_M):\n",
    "\t\t\"\"\"Returns Losses for the current network.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t    gt_M: Tensor, ground truth heat map.\n",
    "\n",
    "\t\tReturns:\n",
    "\t\t    Loss: \n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\t# Assertion\n",
    "\t\tassert isinstance(gt_M, np.ndarray)\n",
    "\t\tif len(gt_M.shape) == 2:\n",
    "\t\t\t# gt_M is a 2D mask\n",
    "\t\t\tgt_M = tf.constant(gt_M.reshape((1,gt_M.shape[0], gt_M.shape[1], 1)), dtype=tf.float32)\n",
    "\t\telif len(gt_M.shape) == 4:\n",
    "\t\t\t# gt_M is SGNet.pre_M\n",
    "\t\t\tgt_M = tf.constant(gt_M, dtype=tf.float32)\n",
    "\t\telse:\n",
    "\t\t\tprint('Unhandled input shape: {0}'.format(gt_M.shape))\n",
    "\n",
    "\t\twith tf.name_scope(tracker.scope) as scope:\n",
    "\t\t\tbeta = tf.constant(tracker.params['wd'], name='beta')\n",
    "\t\t\tloss_rms = tf.reduce_mean(tf.squared_difference(gt_M, tracker.pre_M))\n",
    "\t\t\tloss_wd = [tf.reduce_mean(tf.square(w)) for w in tracker.kernel_weights]\n",
    "\t\t\tloss_wd = beta * tf.add_n(loss_wd)\n",
    "\t\t\ttotal_loss = loss_rms + loss_wd\n",
    "\t\treturn total_loss\n",
    "\n",
    "\t\t@classmethod\n",
    "\t\tdef eadge_RP():\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tThis method propose a series of ROI along eadges\n",
    "\t\t\tfor a given frame. This should be called when particle \n",
    "\t\t\tconfidence below a critical value, which possibly accounts\n",
    "\t\t\tfor object re-appearance.\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tpass\n",
    "\n",
    "\n",
    "\n",
    "class GNet(SGNet):\n",
    "\tdef __init__(self, scope, vgg_conv_shape):\n",
    "\t\t\"\"\"\n",
    "\t\tFixed params once trained in the first frame\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(GNet, self).__init__(scope, vgg_conv_shape)\n",
    "\n",
    "\n",
    "\n",
    "class SNet(SGNet):\n",
    "\tlr = 1e-8\n",
    "\toptimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "\tdef __init__(self, scope, vgg_conv_shape):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialized in the first frame\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(SNet, self).__init__(scope, vgg_conv_shape)\n",
    "\n",
    "\tdef adaptive_finetune(self, sess, best_M):\n",
    "\t\t\"\"\"Finetune SNet with best pre_M predicetd by gNet.\"\"\"\n",
    "        # Upsampling best_M \n",
    "        #bres_M_resized = imresize(best_M, [1, 28, 28, 1], interp='bicubic')\n",
    "        #bres_M_resized = tf.constant(bres_M_resized, dtype=tf.float32)\n",
    "\t\tloss = tracker.loss(best_M)\n",
    "\t\ttrain_op = SNet.optimizer.minimize(loss, var_list=tracker.variables)\n",
    "\t\tsess.run(train_op)\n",
    "\n",
    "\n",
    "\tdef descrimtive_finetune(self, sess, conv4_3_t0, sgt_M, conv4_3_t, pre_M, phi):\n",
    "\t\t# Type and shape check!\n",
    "\t\tsgt_M = tf.constant(sgt_M, dtype=tf.float32)\n",
    "\t\tpre_M = tf.constant(pre_M, dtype=tf.float32)\n",
    "\n",
    "\t\tLoss_t0 = tf.reduce_sum(tf.sqrt(tf.sub(sgt_M, tracker.pre_M)))\n",
    "\t\tfeed_dict_t0 = {tracker.input_maps: conv4_3_t0}\n",
    "\t\ttrain_op_t0 = SNet.optimizer.minimize(Loss_t0, var_list=tracker.variables)\n",
    "\t\t\n",
    "\n",
    "\t\tLoss_t =  tf.reduce_sum((1-phi) * tf.reduce_sum(tf.sqrt(tf.sub(pre_M, tracker.pre_M))))\n",
    "\t\tfeed_dict_t = {tracker.input_maps: conv4_3_t}\n",
    "\t\ttrain_op_t = SNet.optimizer.minimize(Loss_t0, var_list=tracker.variables)\n",
    "\t\t\n",
    "\t\tfor _ in range(20):\n",
    "\t\t\tsess.run(train_op_t0, feed_dict_t0)\n",
    "\t\t\tsess.run(train_op_t, feed_dict_t)\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'GNet_tmp/conv2:0' shape=(1, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnet.pre_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'SNet_tmp/conv2:0' shape=(1, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snet.pre_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 14, 36] conv1 shape\n",
      "[1, 14, 14, 1] conv shape\n",
      "Shape of the out put heat map for GNet_tmp2 is [1, 14, 14, 1]\n",
      "[1, 28, 28, 36] conv1 shape\n",
      "[1, 28, 28, 1] conv shape\n",
      "Shape of the out put heat map for SNet_tmp2 is [1, 28, 28, 1]\n",
      "303295.0\n",
      "349.84\n",
      "244.718\n",
      "181.154\n",
      "139.952\n",
      "111.364\n",
      "90.7019\n",
      "75.5983\n",
      "64.4097\n",
      "56.035\n",
      "49.7111\n",
      "44.8813\n",
      "41.1373\n",
      "38.1913\n",
      "35.8318\n",
      "33.9029\n",
      "32.2921\n",
      "30.9214\n",
      "29.7332\n",
      "28.6851\n",
      "27.7451\n",
      "26.89\n",
      "26.0993\n",
      "25.3572\n",
      "24.6577\n",
      "23.9957\n",
      "23.3655\n",
      "22.7602\n",
      "22.1784\n",
      "21.6183\n",
      "21.0789\n",
      "20.5588\n",
      "20.057\n",
      "19.5725\n",
      "19.1044\n",
      "18.6511\n",
      "18.2121\n",
      "17.7867\n",
      "17.3746\n",
      "16.9753\n",
      "16.5884\n",
      "16.2134\n",
      "15.85\n",
      "15.497\n",
      "15.1536\n",
      "14.8194\n",
      "14.4944\n",
      "14.1781\n",
      "13.8703\n",
      "13.5708\n"
     ]
    }
   ],
   "source": [
    "# Instantiate G and S networks.\n",
    "gnet = GNet('GNet_tmp2', g_sel_maps.shape)\n",
    "snet = SNet('SNet_tmp2', s_sel_maps.shape)\n",
    "\n",
    "## Train G and S nets by minimizing a composite loss.\n",
    "## with feeding selected saliency maps for each networks.\n",
    "feed_dict = {gnet.input_maps: g_sel_maps, snet.input_maps: s_sel_maps}\n",
    "train_sgNet(sess, gnet, snet, sgt_M, ggt_M, feed_dict)\n",
    "s_sel_maps_t0 = s_sel_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  debug t>0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from queue import Queue\n",
    "from scipy.misc import imresize\n",
    "from operator import add\n",
    "\n",
    "def compute_conf(roi, loc_p):\n",
    "\t\"\"\"Helper func for computing confidence\"\"\"\n",
    "\tcx,cy,w,h = loc_p\n",
    "\tconf = np.sum(roi[y-int(0.5*h): y+int(0.5*h), x-int(0.5*w):x+int(0.5*w)])\n",
    "\treturn conf\n",
    "\n",
    "\n",
    "class Tracker:\n",
    "\t\"\"\"\n",
    "\tGeneric tracking model. A location is represented by an affine transformation (e.g., Xt−1), which warps the\n",
    "\tcoordinate system so that the target lies within the unit square. Particles representing possible target locations Xt, \n",
    "\tat time t are sampled according to P(Xt|Xt−1), which in this case is a diagonal-covariance Gaussian centered at Xt−1.\n",
    "\t\n",
    "\tWhere:\n",
    "\tXt = (xt, yt, θt, st, αt, φt)\n",
    "\tdenote x, y translation, rotation angle, scale, aspect ratio, and skew direction at time t.\n",
    "\n",
    "\tP(Xt|Xt−1) = N (Xt; Xt−1, Ψ)\n",
    "\twhere Ψ is a diagonal covariance matrix whose elements are the corresponding variances of affine parameters, assumes the variance of each affine parameter does not change over time\n",
    "\n",
    "\tSee 3.3.1 Dynamic model in http://www.cs.toronto.edu/~dross/ivt/RossLimLinYang_ijcv.pdf for reference\n",
    "\n",
    "\tParticle filter calss\"\"\"\n",
    "\tdef __init__(self, init_location,):\n",
    "\t\tself.conf_q = Queue(maxsize=20)\n",
    "\t\tself.pre_M_q = Queue(maxsize=20)\n",
    "\t\tself.last_two_loc_q = Queue(maxsize=2)\n",
    "\n",
    "\t\tself.location = init_location\n",
    "\t\tself.params = self._init_params(init_location)\n",
    "\n",
    "\n",
    "\n",
    "\tdef _init_params(self, init_location):\n",
    "\t\t\"\"\"Initialize tracker's parameters\"\"\"\n",
    "\n",
    "\t\tparams = {'p_sz': 64, 'p_num': 700, 'min_conf': 0.2, \n",
    "\t\t\t\t'mv_thr': 0.1, 'up_thr': 0.35, 'roi_scale': 2}\n",
    "\t\tdiag_s = np.ceil((init_location[2]**2 + init_location[3]**2)**0.5/7)\n",
    "\t\tparams['aff_sig'] = [diag_s, diag_s, 0.004, 0.0, 0.0, 0]\n",
    "\t\tparams['ratio'] = init_location[2] / params['p_sz']\n",
    "\t\t\n",
    "\t\treturn params\n",
    "\n",
    "\tdef _qs_full(self):\n",
    "\t\tif self.conf_q.full() and self.pre_M_q.full():\n",
    "\t\t\treturn True\n",
    "\t\telse:\n",
    "\t\t\treturn False\n",
    "\n",
    "\tdef gen_best_M(self):\n",
    "\t\t\"\"\"Returns the best pre_M in records.\"\"\"\n",
    "\t\tassert self._qs_full()\n",
    "\n",
    "\t\tpre_Ms = [self.pre_M_q.get() for _ in range(20)]\n",
    "\t\tconfs = [self.conf_q.get() for _ in range(20)]\n",
    "\t\tidx = np.argmax(confs)\n",
    "\t\treturn pre_Ms[idx]\n",
    "\n",
    "\n",
    "\tdef draw_particles(self):\n",
    "\t\t\"\"\"\n",
    "\t\tGenerates particles according to \n",
    "\t\tP(Xt|Xt−1) = N (Xt; Xt−1, Ψ)\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\taff_params: affine parameters, see class doc string for \n",
    "\t\t\t\tspecific element definition.\n",
    "\t\t\t\t[cx, cy, w/p_sz, 0, h/w, 0] for 6 degrees of freendom\n",
    "\t\t\t\t[tlx, tly, w, h] for 4 degrees of freedom.\n",
    "\t\t\t\t.\n",
    "\t\tReturns:\n",
    "\t\t\taff_params_M : self.p_num*dof size matrix,\n",
    "\t\t\t\twhere rows are updated randomly drawed affine \n",
    "\t\t\t\tparams, columns repersent each particles. \n",
    "\t\t\"\"\"\n",
    "\t\tpass\n",
    "\n",
    "\n",
    "\n",
    "\tdef predict_location(self, pre_M, gt_last, resize_factor, t):\n",
    "\t\t\"\"\"\n",
    "\t\tPredict location for each particle. It is calculated by\n",
    "\t\t1. compute the confidence of the i-th candidate, which is \n",
    "\t\t\tthe summation of all the heatmap values within the candidate region.\n",
    "\t\t2. the candidate with the highest confidence value is predicted as target.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\timg_siz: tuple(image height, image width)\n",
    "\t\t\tpre_M: predicted heat map\n",
    "\t\t\tt: index of current frame\n",
    "\t\t\"\"\"\n",
    "\t\tpass\n",
    "\n",
    "\n",
    "\tdef get_most_conf_M(self):\n",
    "\t\t\"\"\"Returns the most confidence heat maps.\"\"\"\n",
    "\n",
    "\t\t# Pull self.conf_records all out, and retrive \n",
    "\t\t# the most confident heat map. \n",
    "\n",
    "\t\treturn updated_gt_M\n",
    "\n",
    "\n",
    "\tdef linear_prediction(self):\n",
    "\t\t\"\"\"\n",
    "\t\tPredicts current location linnearly according\n",
    "\t\tto las two frames location. This may boost the \n",
    "\t\trobustnesss of obejct occlusion.\n",
    "\t\t\"\"\"\n",
    "\t\tpass\n",
    "\n",
    "\tdef distracted(self):\n",
    "\t\t\"\"\"Distracter detection.\"\"\"\n",
    "\n",
    "\t\t# up-sampling pre_M\n",
    "\n",
    "\t\t# Compute confidence according to \n",
    "\t\t# S = with_in / with_out\n",
    "\t\tif self.cur_best_conf <= self.params['min_conf']:\n",
    "\t\t\treturn True\n",
    "\t\telse:\n",
    "\t\t\treturn False\n",
    "\t\t\t\n",
    "\t@classmethod\n",
    "\tdef compute_conf(self, roi, loc_p):\n",
    "\t\t\"\"\"Helper func for computing confidence\"\"\"\n",
    "\t\tx,y,w,h = loc_p\n",
    "\t\tconf = np.sum(roi[y-int(0.5*h): y+int(0.5*h), \\\n",
    "\t\t\t\t\tx-int(0.5*w):x+int(0.5*w)])\n",
    "\t\treturn conf\n",
    "\n",
    "\t@classmethod\n",
    "\tdef aff2loc(self, las_loc, aff_param):\n",
    "\t\t\"\"\"Convert affine params to location.\"\"\"\n",
    "\t\tassert len(aff_param)==4, 'This method only works for dof 4 aff space.'\n",
    "\t\tcur_loc = [i+j for i,j in zip(las_loc, aff_param)]\n",
    "\t\treturn cur_loc\n",
    "\n",
    "\n",
    "class TrackerVanilla(Tracker):\n",
    "\t\"\"\"Vanilla tracker\n",
    "\n",
    "\t\tThe covariance matrix has only 4 degrees of freedom,\n",
    "\t\tspecified by vertical, horizontal translation of the central\n",
    "\t\tpoint, variance of the width, variance of the w/h ratio.\n",
    "\n",
    "\t\tThe corrresponding actual senarios are object replacment,\n",
    "\t\tobject zoom in/out, object rotaion. Should be sufficient \n",
    "\t\tfor most cases of car tracking.\n",
    "\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, init_location):\n",
    "\t\tsuper(TrackerVanilla, self).__init__(init_location)\n",
    "\t\tself._update_params()\n",
    "\n",
    "\tdef _update_params(self):\n",
    "\t\t\"\"\"Update aff_sig param.\"\"\"\n",
    "\t\tself.params['aff_sig'] = [10, 10, 0.04, 0.04]\n",
    "\n",
    "\n",
    "\tdef draw_particles(self, last_location):\n",
    "\t\t\"\"\"\n",
    "\t\tThe covariance matrix has only 4 degrees of freedom,\n",
    "\t\tspecified by vertical, horizontal translation of the central\n",
    "\t\tpoint, variance of the width, variance of the w/h ratio.\n",
    "\n",
    "\t\tThe corrresponding actual senarios are object replacment,\n",
    "\t\tobject zoom in/out, object rotaion. Should be sufficient \n",
    "\t\tfor most cases of car tracking.\n",
    "\n",
    "\t\tArgs: \n",
    "\t\t\tlast_location: [tlx, tly, w, h]\n",
    "\t\t\"\"\"\n",
    "\t\t# Define degrees of freedom \n",
    "\t\tdof = len(self.params['aff_sig'])\n",
    "\n",
    "\t\t# Construct an p_num*6 size matrix with with each \n",
    "\t\t# column repersents one particle\n",
    "\n",
    "\t\t#aff_params_M = np.kron(np.ones((self.params['p_num'],1)), np.array(aff_params))\n",
    "\n",
    "\t\t# First onstruct a p_num*dof size normal distribution with \n",
    "\t\t# mean 0 and sigma 1\n",
    "\t\trand_norml_M = np.array([np.random.standard_normal(dof) for _ in range(self.params['p_num'])])\n",
    "\n",
    "\t\t# Then construct a affine sigma matrix\n",
    "\t\taff_sig_M = np.kron(np.ones((self.params['p_num'], 1)), self.params['aff_sig'])\n",
    "\n",
    "\t\t# Update particles \n",
    "\t\tself.aff_params_M = rand_norml_M * aff_sig_M\n",
    "\n",
    "\n",
    "\tdef predict_location(self, pre_M, gt_last, resize_factor, t, roi_size):\n",
    "\t\t\"\"\"\n",
    "\t\tPredict location for each particle. It is calculated by\n",
    "\t\t1. compute the confidence of the i-th candidate, which is \n",
    "\t\t\tthe summation of all the heatmap values within the candidate region.\n",
    "\t\t2. the candidate with the highest confidence value is predicted as target.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\timg_siz: tuple(image height, image width)\n",
    "\t\t\tpre_M: predicted heat map\n",
    "\t\t\tt: index of current frame\n",
    "\t\t\"\"\"\n",
    "\t\t# transform self.aff_params_M to location_M with each column \n",
    "\t\t# repersent [cx, cy, w, h] in the pre_M heat map\n",
    "\t\tloc_M = np.zeros(self.aff_params_M.shape)\n",
    "\t\ttlx, tly, w, h = gt\n",
    "\t\tcx, cy = roi_size // 2, roi_size // 2\n",
    "\t\tloc_M[:, 0] = cx\n",
    "\t\tloc_M[:, 1] = cy\n",
    "\t\tloc_M[:, 2] = resize_factor * w \n",
    "\t\tloc_M[:, 3] = resize_factor * h\n",
    "\t\tloc_M += self.aff_params_M\n",
    "\t\tloc_M = loc_M.astype(np.int)\n",
    "\n",
    "\t\t# Upsampling pre_M bicubicly to roi_size\n",
    "\t\tpre_M_resized = imresize(pre_M[0,:,:,0], [roi_size, roi_size], interp='bicubic')\n",
    "\n",
    "\t\t# Compute conf for each particle \n",
    "\t\tconf_lsit = []\n",
    "\t\tfor p_i_loc in loc_M:\n",
    "\t\t\tconf_i = self.compute_conf(pre_M_resized, p_i_loc)\n",
    "\t\t\tconf_lsit += [conf_i]\n",
    "\n",
    "\t\t# Get index and conf score of of the most confident one\n",
    "\t\tidx = np.argmax(conf_lsit)\n",
    "\t\tself.cur_best_conf = conf_lsit[idx]\n",
    "\t\tself.conf_q.put(conf_lsit[idx])\n",
    "\n",
    "\t\t# Get the corresponding aff_param which is then\n",
    "\t\t# used to predicted the cureent best location\n",
    "\t\tbest_aff =  self.aff_params_M[idx]\n",
    "\t\tprint('The affine paramters: [dx,dy,dw,dh] is {0}'.format(best_aff))\n",
    "\t\tself.pre_location = self.aff2loc(gt_last, best_aff)\n",
    "\n",
    "\t\t# Stack into records queue\n",
    "\n",
    "\n",
    "\t\treturn self.pre_location\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker = TrackerVanilla(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Iter imgs\n",
    "gt_last = gt \n",
    "#for i in range(FLAGS.iter_max):\n",
    "# Gnerates next frame infos\n",
    "img, gt_cur, t  = next(inputProducer.gen_img)\n",
    "\n",
    "## Crop a rectangle ROI region centered at last target location.\n",
    "roi, _, resize_factor = inputProducer.extract_roi(img, gt_last)\n",
    "\n",
    "## Perform Target localiation predicted by GNet\n",
    "# Get heat map predicted by GNet\n",
    "feed_dict_vgg = {vgg.imgs : [roi]}\n",
    "s_maps, g_maps = sess.run([vgg.conv4_3, vgg.conv5_3], feed_dict=feed_dict_vgg)\n",
    "s_sel_maps = s_maps[...,s_idx] # np.ndarray, shape = [1,28,28,num_sel]?\n",
    "g_sel_maps = g_maps[...,g_idx]\n",
    "\n",
    "feed_dict_g = { gnet.input_maps: g_sel_maps}\n",
    "pre_M = sess.run(gnet.pre_M, feed_dict=feed_dict_g)\n",
    "\n",
    "tracker.draw_particles(gt_last)\n",
    "pre_loc = tracker.predict_location(pre_M, gt_last, resize_factor, t, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The affine paramters: [dx,dy,dw,dh] is [ 11.64488943 -29.72706869   0.04514857  -0.06402944]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snet adaptive debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.pre_M_q.full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-c085d3899d30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_M\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_best_M\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-113-93efe44734a8>\u001b[0m in \u001b[0;36mgen_best_M\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mgen_best_M\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[1;34m\"\"\"Returns the best pre_M in records.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qs_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mpre_Ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_M_q\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_M = tracker.gen_best_M()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 14, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 14 and 28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, debug_python_shape_fn)\u001b[0m\n\u001b[0;32m    618\u001b[0m       output_shapes = pywrap_tensorflow.RunCppShapeInference(\n\u001b[1;32m--> 619\u001b[1;33m           node_def_str, input_shapes, status)\n\u001b[0m\u001b[0;32m    620\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    460\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    462\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 14 and 28",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-e3c34a93b5ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_finetune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_M\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-18da70d66d08>\u001b[0m in \u001b[0;36madaptive_finetune\u001b[1;34m(self, sess, best_M)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m#bres_M_resized = imresize(best_M, [1, 28, 28, 1], interp='bicubic')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m#bres_M_resized = tf.constant(bres_M_resized, dtype=tf.float32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_M\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-18da70d66d08>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, gt_M)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                         \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'wd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'beta'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                         \u001b[0mloss_rms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_M\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_M\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m                         \u001b[0mloss_wd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                         \u001b[0mloss_wd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_wd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msquared_difference\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2344\u001b[0m   \"\"\"\n\u001b[1;32m-> 2345\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SquaredDifference\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2346\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                            op_def=op_def)\n\u001b[0m\u001b[0;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2333\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2334\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2335\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2336\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2337\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1722\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[0;32m   1723\u001b[0m                          % op.type)\n\u001b[1;32m-> 1724\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1725\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, debug_python_shape_fn)\u001b[0m\n\u001b[0;32m    619\u001b[0m           node_def_str, input_shapes, status)\n\u001b[0;32m    620\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m   \u001b[1;31m# Convert TensorShapeProto values in output_shapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 14 and 28"
     ]
    }
   ],
   "source": [
    "snet.adaptive_finetune(sess, pre_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snet Descrimtive update debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tracker.distracted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xlws/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:83: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (224, 224, 3) for Tensor 'SNet_tmp2/selected_maps:0', which has shape '(1, 28, 28, 384)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-9c328f5ccdb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mphi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_mask_phi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescrimtive_finetune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_sel_maps_t0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgt_M\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_sel_maps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpre_M\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_M\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Use location predicted by SNet.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-18da70d66d08>\u001b[0m in \u001b[0;36mdescrimtive_finetune\u001b[1;34m(self, sess, conv4_3_t0, sgt_M, conv4_3_t, pre_M, phi)\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op_t0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_t0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 717\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    718\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/xlws/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    895\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (224, 224, 3) for Tensor 'SNet_tmp2/selected_maps:0', which has shape '(1, 28, 28, 384)'"
     ]
    }
   ],
   "source": [
    "phi = gen_mask_phi(roi.shape, pre_loc)\n",
    "snet.descrimtive_finetune(sess, s_sel_maps_t0, sgt_M, roi, s_sel_maps, phi)\n",
    "pre_M = sess.run(snet.pre_M, feed_dict=feed_dict)\n",
    "\n",
    "# Use location predicted by SNet.\n",
    "pre_loc = tracker.predict_location(pre_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
