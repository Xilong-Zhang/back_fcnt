{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the first image...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main script for FCNT tracker. \n",
    "\"\"\"\n",
    "\n",
    "# Import custom class and functions\n",
    "from inputproducer import LiveInput\n",
    "from tracker import TrackerContour\n",
    "from vgg16 import Vgg16\n",
    "from sgnet import GNet, SNet\n",
    "from utils import img_with_bbox, IOU_eval, select_fms\n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from scipy.misc import imresize\n",
    "from subprocess import call\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "tf.app.flags.DEFINE_integer('iter_epoch_sg', 7,\n",
    "                          \"\"\"Number of epoches for trainning\"\"\"\n",
    "                          \"\"\"SGnet works\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size', 45,\n",
    "                          \"\"\"Batch size for SGNet trainning\"\"\"\n",
    "                          \"\"\"SGnet works\"\"\")\n",
    "tf.app.flags.DEFINE_integer('n_samples_per_batch', 5000,\n",
    "                          \"\"\"Number of samples per batch for trainning\"\"\"\n",
    "                          \"\"\"SGnet works\"\"\")\n",
    "tf.app.flags.DEFINE_integer('iter_max', 1349,\n",
    "\t\t\t\t\t\t\t\"\"\"Max iter times through imgs\"\"\")\n",
    "tf.app.flags.DEFINE_integer('sel_num', 354,\n",
    "                          \"\"\"Number of feature maps selected.\"\"\")\n",
    "tf.app.flags.DEFINE_string('model_name', 'first_LiveFaceXL',\n",
    "\t\t\t\t\t\t\"\"\"true for train, false for eval\"\"\")\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "## Define varies pathes\n",
    "DATA_ROOT = 'data/Car1'\n",
    "PRE_ROOT = os.path.join(DATA_ROOT, 'img_loc')\n",
    "IMG_PATH = os.path.join(DATA_ROOT, 'img')\n",
    "GT_PATH = os.path.join(DATA_ROOT, 'groundtruth_rect.txt')\n",
    "VGG_WEIGHTS_PATH = 'vgg16_weights.npz'\n",
    "\n",
    "\n",
    "#if not os.path.isdir(PRE_ROOT):\n",
    "#    os.mkdir(PRE_ROOT)\n",
    "\n",
    "\n",
    "TB_SUMMARY = os.path.join('tb_summary', FLAGS.model_name)\n",
    "if not os.path.isdir('tb_summary'):\n",
    "    os.mkdir('tb_summary')\n",
    "if not os.path.isdir(TB_SUMMARY):\n",
    "    os.mkdir(TB_SUMMARY)\n",
    "\n",
    "CKPT_PATH = 'checkpoint'\n",
    "if not os.path.isdir(CKPT_PATH):\n",
    "    os.mkdir(CKPT_PATH)\n",
    "\n",
    "model_name = FLAGS.model_name+'.ckpt'\n",
    "CKPT_MODEL = os.path.join(CKPT_PATH, model_name)\n",
    "\n",
    "\n",
    "def init_vgg(roi_t0, predict=True):\n",
    "    \"\"\"\n",
    "    Initialize a tf.Session and a vgg16 graph. Followed\n",
    "    by forwarding the vgg net once to predict top5 class labels\n",
    "    for image generated in the first frame.\n",
    "\n",
    "    Args:\n",
    "        roi_t0: np.ndarray with shape (28x28x3), extracted roi in the first frame.\n",
    "    Returns:\n",
    "        sess: tf.Session object.\n",
    "        vgg: Vgg16 class instance.\n",
    "    \"\"\"\n",
    "    print('Classify it with a pre-trained Vgg16 model.')\n",
    "    t_start = time.time()\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    vgg = Vgg16(VGG_WEIGHTS_PATH, sess)\n",
    "    if predict:\n",
    "        vgg.print_prob(roi_t0, sess)\n",
    "    print('Forwarding the vgg net cost : %.2f s'%(time.time() - t_start))\n",
    "    return sess, vgg\n",
    "\n",
    "def gen_sel_maps(sess, roi, vgg, idx_c4, idx_c5):\n",
    "    \"\"\"Returns selected c4 and c5 maps\"\"\"\n",
    "    if len(roi.shape) == 3: roi = [roi]\n",
    "    fd = {vgg.imgs : roi}\n",
    "    c4_arr, c5_arr = sess.run([vgg.conv4_3_norm, vgg.conv5_3_norm], feed_dict=fd)\n",
    "    c4_maps = c4_arr[...,idx_c4]\n",
    "    c5_maps = c5_arr[...,idx_c5]\n",
    "    return c4_maps, c5_maps\n",
    "\n",
    "\n",
    "def train_SGNets(sess, img, gt, vgg, snet, gnet, inputProducer, idx_c4, idx_c5):\n",
    "    \"\"\"\n",
    "    Train SGnets' variables by minimizing a composite L2 regression losses.\n",
    "\n",
    "    Args:\n",
    "        sess: tf.Session object.\n",
    "        vgg: Vgg16 class instance.\n",
    "        snet: SNet class instance.\n",
    "        gnet:  GNet class instance.\n",
    "        inputProducer: InputProducer class instance.\n",
    "    \"\"\"\n",
    "    gnet.params['wd'] = 0.5\n",
    "    gloss, sloss = gnet.loss(), snet.loss()\n",
    "    loss = gloss  + sloss\n",
    "    tf.scalar_summary('loss', loss)\n",
    "    writer = tf.train.SummaryWriter(TB_SUMMARY, sess.graph)\n",
    "    \n",
    "    vars_train = gnet.variables + snet.variables\n",
    "\n",
    "    # Backprop using SGD and updates vgg variables and sgnets variables\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    lr_exp = tf.train.exponential_decay(\n",
    "            0.25, # Initial learning rate \n",
    "            global_step, \n",
    "            1000, # Decay steps \n",
    "            0.8, # Decay rate \n",
    "            name='sg_lr')\n",
    "\n",
    "    tf.scalar_summary('Learning rate', lr_exp)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr_exp)\n",
    "    train_op = optimizer.minimize(loss, var_list= vars_train, global_step=global_step)\n",
    "    merged = tf.merge_all_summaries()\n",
    "    \n",
    "    print('Generating batches from img size:%s  for trainning.'%str(img.shape))\n",
    "    sample_batches, target_batches = inputProducer.gen_batches(img, gt, n_samples=FLAGS.n_samples_per_batch, batch_sz=FLAGS.batch_size, pos_ratio=0.5, scale_factors=np.arange(0.5, 5., 0.2)) #np.array([1]))#\n",
    "    print('Start training the SGNets........ for %s epoches'%FLAGS.iter_epoch_sg)\n",
    "    saver = tf.train.Saver()\n",
    "    step = 1\n",
    "    loss_list = []\n",
    "    for ep in range(FLAGS.iter_epoch_sg):\n",
    "        print('Total batches in each epoch: ', len(sample_batches))\n",
    "        for roi, target in zip(sample_batches, target_batches):\n",
    "            #roi[roi>0] = 1 # neglect gaussian..set to 1 for target arear\n",
    "            \n",
    "            t = time.time()\n",
    "            c4_maps, c5_maps = gen_sel_maps(sess, roi, vgg, idx_c4, idx_c5)\n",
    "            \n",
    "            fd = {gnet.input_maps: c5_maps, gnet.gt_M: target, \n",
    "                  snet.input_maps: c4_maps, snet.gt_M: target}\n",
    "            \n",
    "            # Initialization \n",
    "            if step == 1:\n",
    "                loss_g = 10\n",
    "                init_s = 0\n",
    "                while loss_g > 1.2:\n",
    "                    init_s += 1\n",
    "                    sess.run(tf.initialize_variables(gnet.variables))\n",
    "                    loss_g = sess.run(gloss, feed_dict=fd)\n",
    "                    print('Initial Gnet Loss: ', loss_g, 'In steps: ', init_s)\n",
    "                sess.run(tf.initialize_variables(snet.variables + [global_step]))\n",
    "                \n",
    "            \n",
    "            pre_M_g, l, _, lr = sess.run([gnet.pre_M, loss, train_op, lr_exp], feed_dict=fd)\n",
    "            \n",
    "            loss_list += [l]\n",
    "            if l <= 0.1:\n",
    "                print('break learning!')\n",
    "                break\n",
    "            if step % 20 == 0:\n",
    "                \n",
    "                loss_ac = np.diff(np.diff(loss_list[-19:]))\n",
    "                loss_ac_summary = tf.scalar_summary('Loss acceleration', loss_ac.mean())\n",
    "                \n",
    "                \n",
    "                summary_img_g = tf.image_summary('pre_M', \n",
    "                                                 np.repeat(pre_M_g[...,np.newaxis], 3, axis=-1), name='GMap')\n",
    "\n",
    "                summary, img_summary_g, ac_loss_summary = sess.run([merged, summary_img_g, loss_ac_summary], feed_dict=fd)\n",
    "\n",
    "                writer.add_summary(summary, global_step=step)\n",
    "                writer.add_summary(img_summary_g, global_step=step)\n",
    "                writer.add_summary(ac_loss_summary, global_step=step)\n",
    "                \n",
    "                loss_std = np.std(loss_list[-19:])\n",
    "                if loss_std <= 0.007:\n",
    "                    \n",
    "                    print('Stop learning??! Last 10 batches Loss Std: ', loss_std)\n",
    "                    #break\n",
    "\n",
    "            #if step % 20 == 0:\n",
    "                print('Epoch: ', ep+1, 'Step: ', (ep+1)*step, 'Loss : %.2f'%l, \\\n",
    "                    'Speed: %.2f second/batch'%(time.time()-t), 'Lr: ', lr)\n",
    "                #saver.save(sess, CKPT_MODEL)\n",
    "            step += 1\n",
    "\n",
    "\n",
    "\n",
    "print('Reading the first image...')\n",
    "t_start = time.time()\n",
    "## Instantiate inputProducer and retrive the first img\n",
    "# with associated ground truth. \n",
    "inputProducer = LiveInput()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#import argparse\n",
    "import cv2\n",
    "\n",
    "# initialize the list of reference points and boolean indicating\n",
    "# whether cropping is being performed or not\n",
    "refPt = []\n",
    "cropping = False\n",
    "\n",
    "def click_and_crop(event, x, y, flags, param):\n",
    "    # grab references to the global variables\n",
    "    global refPt, cropping\n",
    "\n",
    "    # if the left mouse button was clicked, record the starting\n",
    "    # (x, y) coordinates and indicate that cropping is being\n",
    "    # performed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        refPt = [(x, y)]\n",
    "        #cropping = True\n",
    "\n",
    "    # check to see if the left mouse button was released\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        # record the ending (x, y) coordinates and indicate that\n",
    "        # the cropping operation is finished\n",
    "        refPt.append((x, y))\n",
    "        #cropping = False\n",
    "\n",
    "        # draw a rectangle around the region of interest\n",
    "        #cv2.rectangle(image, refPt[0], refPt[1], (0, 255, 0), 2)\n",
    "        #cv2.imshow(\"image\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def refPt_2_gt(refPt):\n",
    "    p1, p2 = refPt\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    return (x1, y1, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 281, 110, 158) gt in first!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/makehave/xlrepo/back_fcnt/inputproducer.py:110: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  roi = convas[cy-half:cy+half, cx-half:cx+half, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify it with a pre-trained Vgg16 model.\n",
      "barbershop 0.256563\n",
      "cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM 0.0426335\n",
      "cellular telephone, cellular phone, cellphone, cell, mobile phone 0.0425359\n",
      "web site, website, internet site, site 0.0375001\n",
      "barber chair 0.0360401\n",
      "Forwarding the vgg net cost : 4.21 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/makehave/xlrepo/back_fcnt/utils.py:80: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  conf_i = roi[c-h_half:c+h_half, c-w_half:c+w_half].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found saved model checkpoint/LiveFaceXL.ckpt. Trainning! \n",
      "Generating batches from img size:(480, 640, 3)  for trainning.\n",
      "Start training the SGNets........ for 7 epoches\n",
      "Total batches in each epoch:  223\n",
      "Initial Gnet Loss:  2.18148 In steps:  1\n",
      "Initial Gnet Loss:  3.31207 In steps:  2\n",
      "Initial Gnet Loss:  3.09164 In steps:  3\n",
      "Initial Gnet Loss:  2.27267 In steps:  4\n",
      "Initial Gnet Loss:  11.2435 In steps:  5\n",
      "Initial Gnet Loss:  3.34961 In steps:  6\n",
      "Initial Gnet Loss:  2.85988 In steps:  7\n",
      "Initial Gnet Loss:  1.68124 In steps:  8\n",
      "Initial Gnet Loss:  1.94571 In steps:  9\n",
      "Initial Gnet Loss:  10.2861 In steps:  10\n",
      "Initial Gnet Loss:  4.28106 In steps:  11\n",
      "Initial Gnet Loss:  2.84455 In steps:  12\n",
      "Initial Gnet Loss:  9.34216 In steps:  13\n",
      "Initial Gnet Loss:  2.23038 In steps:  14\n",
      "Initial Gnet Loss:  8.6919 In steps:  15\n",
      "Initial Gnet Loss:  10.1598 In steps:  16\n",
      "Initial Gnet Loss:  2.49069 In steps:  17\n",
      "Initial Gnet Loss:  1.80017 In steps:  18\n",
      "Initial Gnet Loss:  4.79867 In steps:  19\n",
      "Initial Gnet Loss:  2.37128 In steps:  20\n",
      "Initial Gnet Loss:  3.68832 In steps:  21\n",
      "Initial Gnet Loss:  8.57959 In steps:  22\n",
      "Initial Gnet Loss:  12.7375 In steps:  23\n",
      "Initial Gnet Loss:  2.68575 In steps:  24\n",
      "Initial Gnet Loss:  1.72634 In steps:  25\n",
      "Initial Gnet Loss:  11.2262 In steps:  26\n",
      "Initial Gnet Loss:  3.65703 In steps:  27\n",
      "Initial Gnet Loss:  25.7117 In steps:  28\n",
      "Initial Gnet Loss:  4.35884 In steps:  29\n",
      "Initial Gnet Loss:  2.28129 In steps:  30\n",
      "Initial Gnet Loss:  1.8498 In steps:  31\n",
      "Initial Gnet Loss:  9.40716 In steps:  32\n",
      "Initial Gnet Loss:  18.0603 In steps:  33\n",
      "Initial Gnet Loss:  3.72333 In steps:  34\n",
      "Initial Gnet Loss:  14.1125 In steps:  35\n",
      "Initial Gnet Loss:  3.31989 In steps:  36\n",
      "Initial Gnet Loss:  2.01372 In steps:  37\n",
      "Initial Gnet Loss:  9.16321 In steps:  38\n",
      "Initial Gnet Loss:  3.36694 In steps:  39\n",
      "Initial Gnet Loss:  3.20474 In steps:  40\n",
      "Initial Gnet Loss:  5.71776 In steps:  41\n",
      "Initial Gnet Loss:  2.04852 In steps:  42\n",
      "Initial Gnet Loss:  3.49606 In steps:  43\n",
      "Initial Gnet Loss:  4.10197 In steps:  44\n",
      "Initial Gnet Loss:  2.751 In steps:  45\n",
      "Initial Gnet Loss:  1.95761 In steps:  46\n",
      "Initial Gnet Loss:  8.35085 In steps:  47\n",
      "Initial Gnet Loss:  3.64169 In steps:  48\n",
      "Initial Gnet Loss:  2.80062 In steps:  49\n",
      "Initial Gnet Loss:  2.54452 In steps:  50\n",
      "Initial Gnet Loss:  2.14919 In steps:  51\n",
      "Initial Gnet Loss:  2.19727 In steps:  52\n",
      "Initial Gnet Loss:  2.21335 In steps:  53\n",
      "Initial Gnet Loss:  3.35825 In steps:  54\n",
      "Initial Gnet Loss:  1.7512 In steps:  55\n",
      "Initial Gnet Loss:  2.33524 In steps:  56\n",
      "Initial Gnet Loss:  9.7267 In steps:  57\n",
      "Initial Gnet Loss:  1.91911 In steps:  58\n",
      "Initial Gnet Loss:  2.59643 In steps:  59\n",
      "Initial Gnet Loss:  6.4072 In steps:  60\n",
      "Initial Gnet Loss:  3.42462 In steps:  61\n",
      "Initial Gnet Loss:  4.32716 In steps:  62\n",
      "Initial Gnet Loss:  4.36898 In steps:  63\n",
      "Initial Gnet Loss:  4.02633 In steps:  64\n",
      "Initial Gnet Loss:  1.80736 In steps:  65\n",
      "Initial Gnet Loss:  4.01369 In steps:  66\n",
      "Initial Gnet Loss:  4.7742 In steps:  67\n",
      "Initial Gnet Loss:  11.3857 In steps:  68\n",
      "Initial Gnet Loss:  8.90862 In steps:  69\n",
      "Initial Gnet Loss:  12.7295 In steps:  70\n",
      "Initial Gnet Loss:  2.85685 In steps:  71\n",
      "Initial Gnet Loss:  5.28943 In steps:  72\n",
      "Initial Gnet Loss:  2.95143 In steps:  73\n",
      "Initial Gnet Loss:  2.22844 In steps:  74\n",
      "Initial Gnet Loss:  4.30164 In steps:  75\n",
      "Initial Gnet Loss:  3.69416 In steps:  76\n",
      "Initial Gnet Loss:  2.37301 In steps:  77\n",
      "Initial Gnet Loss:  2.26888 In steps:  78\n",
      "Initial Gnet Loss:  2.35792 In steps:  79\n",
      "Initial Gnet Loss:  2.54596 In steps:  80\n",
      "Initial Gnet Loss:  4.385 In steps:  81\n",
      "Initial Gnet Loss:  2.75852 In steps:  82\n",
      "Initial Gnet Loss:  32.6758 In steps:  83\n",
      "Initial Gnet Loss:  4.57035 In steps:  84\n",
      "Initial Gnet Loss:  4.87326 In steps:  85\n",
      "Initial Gnet Loss:  2.01522 In steps:  86\n",
      "Initial Gnet Loss:  3.78726 In steps:  87\n",
      "Initial Gnet Loss:  1.90129 In steps:  88\n",
      "Initial Gnet Loss:  1.28748 In steps:  89\n",
      "Initial Gnet Loss:  10.1412 In steps:  90\n",
      "Initial Gnet Loss:  1.61368 In steps:  91\n",
      "Initial Gnet Loss:  1.05697 In steps:  92\n",
      "Epoch:  1 Step:  20 Loss : 1.79 Speed: 1.00 second/batch Lr:  0.248942\n",
      "Epoch:  1 Step:  40 Loss : 1.60 Speed: 1.04 second/batch Lr:  0.247834\n",
      "Epoch:  1 Step:  60 Loss : 1.53 Speed: 1.02 second/batch Lr:  0.24673\n",
      "Epoch:  1 Step:  80 Loss : 1.76 Speed: 1.04 second/batch Lr:  0.245632\n",
      "Epoch:  1 Step:  100 Loss : 1.46 Speed: 1.01 second/batch Lr:  0.244538\n",
      "Epoch:  1 Step:  120 Loss : 1.34 Speed: 1.04 second/batch Lr:  0.243449\n",
      "Epoch:  1 Step:  140 Loss : 1.35 Speed: 1.05 second/batch Lr:  0.242365\n",
      "Epoch:  1 Step:  160 Loss : 1.39 Speed: 1.04 second/batch Lr:  0.241286\n",
      "Epoch:  1 Step:  180 Loss : 1.33 Speed: 1.01 second/batch Lr:  0.240211\n",
      "Epoch:  1 Step:  200 Loss : 1.44 Speed: 1.04 second/batch Lr:  0.239141\n",
      "Epoch:  1 Step:  220 Loss : 1.40 Speed: 1.02 second/batch Lr:  0.238077\n",
      "Total batches in each epoch:  223\n",
      "Epoch:  2 Step:  480 Loss : 1.29 Speed: 1.03 second/batch Lr:  0.237016\n",
      "Epoch:  2 Step:  520 Loss : 1.25 Speed: 0.99 second/batch Lr:  0.235961\n",
      "Epoch:  2 Step:  560 Loss : 1.40 Speed: 1.06 second/batch Lr:  0.23491\n",
      "Epoch:  2 Step:  600 Loss : 1.25 Speed: 1.06 second/batch Lr:  0.233864\n",
      "Epoch:  2 Step:  640 Loss : 1.29 Speed: 1.03 second/batch Lr:  0.232823\n",
      "Epoch:  2 Step:  680 Loss : 1.25 Speed: 1.01 second/batch Lr:  0.231786\n",
      "Epoch:  2 Step:  720 Loss : 1.23 Speed: 1.02 second/batch Lr:  0.230754\n",
      "Epoch:  2 Step:  760 Loss : 1.21 Speed: 1.02 second/batch Lr:  0.229727\n",
      "Epoch:  2 Step:  800 Loss : 1.24 Speed: 1.04 second/batch Lr:  0.228704\n",
      "Epoch:  2 Step:  840 Loss : 1.23 Speed: 0.99 second/batch Lr:  0.227685\n",
      "Epoch:  2 Step:  880 Loss : 1.23 Speed: 1.06 second/batch Lr:  0.226671\n",
      "Total batches in each epoch:  223\n",
      "Epoch:  3 Step:  1380 Loss : 1.28 Speed: 1.00 second/batch Lr:  0.225662\n",
      "Epoch:  3 Step:  1440 Loss : 1.20 Speed: 1.04 second/batch Lr:  0.224657\n",
      "Epoch:  3 Step:  1500 Loss : 1.19 Speed: 1.01 second/batch Lr:  0.223657\n",
      "Epoch:  3 Step:  1560 Loss : 1.20 Speed: 1.05 second/batch Lr:  0.222661\n",
      "Epoch:  3 Step:  1620 Loss : 1.19 Speed: 1.03 second/batch Lr:  0.221669\n",
      "Epoch:  3 Step:  1680 Loss : 1.20 Speed: 1.04 second/batch Lr:  0.220682\n",
      "Epoch:  3 Step:  1740 Loss : 1.19 Speed: 1.01 second/batch Lr:  0.2197\n",
      "Epoch:  3 Step:  1800 Loss : 1.17 Speed: 1.06 second/batch Lr:  0.218721\n",
      "Epoch:  3 Step:  1860 Loss : 1.17 Speed: 1.01 second/batch Lr:  0.217747\n",
      "Epoch:  3 Step:  1920 Loss : 1.18 Speed: 1.05 second/batch Lr:  0.216778\n",
      "Epoch:  3 Step:  1980 Loss : 1.20 Speed: 1.01 second/batch Lr:  0.215812\n",
      "Total batches in each epoch:  223\n",
      "Epoch:  4 Step:  2720 Loss : 1.17 Speed: 1.03 second/batch Lr:  0.214851\n",
      "Epoch:  4 Step:  2800 Loss : 1.18 Speed: 1.01 second/batch Lr:  0.213895\n",
      "Epoch:  4 Step:  2880 Loss : 1.19 Speed: 1.03 second/batch Lr:  0.212942\n",
      "Epoch:  4 Step:  2960 Loss : 1.18 Speed: 1.01 second/batch Lr:  0.211994\n",
      "Epoch:  4 Step:  3040 Loss : 1.22 Speed: 1.06 second/batch Lr:  0.21105\n",
      "Epoch:  4 Step:  3120 Loss : 1.15 Speed: 1.02 second/batch Lr:  0.21011\n",
      "Epoch:  4 Step:  3200 Loss : 1.17 Speed: 1.06 second/batch Lr:  0.209175\n",
      "Epoch:  4 Step:  3280 Loss : 1.18 Speed: 1.03 second/batch Lr:  0.208243\n",
      "Epoch:  4 Step:  3360 Loss : 1.14 Speed: 1.04 second/batch Lr:  0.207316\n",
      "Epoch:  4 Step:  3440 Loss : 1.16 Speed: 1.03 second/batch Lr:  0.206393\n",
      "Epoch:  4 Step:  3520 Loss : 1.17 Speed: 1.07 second/batch Lr:  0.205474\n",
      "Total batches in each epoch:  223\n",
      "Epoch:  5 Step:  4500 Loss : 1.17 Speed: 1.05 second/batch Lr:  0.204559\n",
      "Epoch:  5 Step:  4600 Loss : 1.16 Speed: 1.06 second/batch Lr:  0.203648\n",
      "Epoch:  5 Step:  4700 Loss : 1.15 Speed: 1.07 second/batch Lr:  0.202741\n",
      "Epoch:  5 Step:  4800 Loss : 1.15 Speed: 1.02 second/batch Lr:  0.201838\n",
      "Epoch:  5 Step:  4900 Loss : 1.18 Speed: 1.04 second/batch Lr:  0.200939\n",
      "Epoch:  5 Step:  5000 Loss : 1.16 Speed: 1.01 second/batch Lr:  0.200045\n",
      "Epoch:  5 Step:  5100 Loss : 1.13 Speed: 1.01 second/batch Lr:  0.199154\n",
      "Epoch:  5 Step:  5200 Loss : 1.16 Speed: 1.02 second/batch Lr:  0.198267\n",
      "Epoch:  5 Step:  5300 Loss : 1.15 Speed: 1.04 second/batch Lr:  0.197384\n",
      "Epoch:  5 Step:  5400 Loss : 1.15 Speed: 1.01 second/batch Lr:  0.196505\n",
      "Epoch:  5 Step:  5500 Loss : 1.18 Speed: 1.07 second/batch Lr:  0.19563\n",
      "Total batches in each epoch:  223\n",
      "Epoch:  6 Step:  6720 Loss : 1.14 Speed: 1.05 second/batch Lr:  0.194759\n",
      "Epoch:  6 Step:  6840 Loss : 1.13 Speed: 1.06 second/batch Lr:  0.193892\n",
      "Epoch:  6 Step:  6960 Loss : 1.13 Speed: 1.04 second/batch Lr:  0.193028\n",
      "Epoch:  6 Step:  7080 Loss : 1.15 Speed: 1.04 second/batch Lr:  0.192169\n",
      "Epoch:  6 Step:  7200 Loss : 1.15 Speed: 1.03 second/batch Lr:  0.191313\n",
      "Epoch:  6 Step:  7320 Loss : 1.15 Speed: 1.07 second/batch Lr:  0.190461\n",
      "Epoch:  6 Step:  7440 Loss : 1.14 Speed: 1.05 second/batch Lr:  0.189613\n",
      "Epoch:  6 Step:  7560 Loss : 1.11 Speed: 1.06 second/batch Lr:  0.188769\n",
      "Epoch:  6 Step:  7680 Loss : 1.14 Speed: 1.02 second/batch Lr:  0.187928\n",
      "Epoch:  6 Step:  7800 Loss : 1.13 Speed: 1.06 second/batch Lr:  0.187091\n",
      "Epoch:  6 Step:  7920 Loss : 1.13 Speed: 1.01 second/batch Lr:  0.186258\n",
      "Total batches in each epoch:  223\n",
      "Epoch:  7 Step:  9380 Loss : 1.13 Speed: 1.06 second/batch Lr:  0.185429\n",
      "Epoch:  7 Step:  9520 Loss : 1.13 Speed: 1.03 second/batch Lr:  0.184603\n",
      "Epoch:  7 Step:  9660 Loss : 1.12 Speed: 1.03 second/batch Lr:  0.183781\n",
      "Epoch:  7 Step:  9800 Loss : 1.14 Speed: 1.06 second/batch Lr:  0.182963\n",
      "Epoch:  7 Step:  9940 Loss : 1.12 Speed: 1.01 second/batch Lr:  0.182148\n",
      "Epoch:  7 Step:  10080 Loss : 1.15 Speed: 1.02 second/batch Lr:  0.181337\n",
      "Epoch:  7 Step:  10220 Loss : 1.12 Speed: 1.00 second/batch Lr:  0.18053\n",
      "Epoch:  7 Step:  10360 Loss : 1.14 Speed: 1.06 second/batch Lr:  0.179726\n",
      "Epoch:  7 Step:  10500 Loss : 1.11 Speed: 0.99 second/batch Lr:  0.178925\n",
      "Epoch:  7 Step:  10640 Loss : 1.11 Speed: 1.03 second/batch Lr:  0.178129\n",
      "Epoch:  7 Step:  10780 Loss : 1.11 Speed: 0.98 second/batch Lr:  0.177335\n",
      "Epoch:  7 Step:  10920 Loss : 1.10 Speed: 1.06 second/batch Lr:  0.176546\n",
      "Classify it with a pre-trained Vgg16 model.\n",
      "web site, website, internet site, site 0.122\n",
      "spotlight, spot 0.0952951\n",
      "barbershop 0.0326598\n",
      "cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM 0.0289198\n",
      "television, television system 0.0266394\n",
      "Forwarding the vgg net cost : 19.40 s\n",
      "Found saved model checkpoint/LiveFaceXL.ckpt, restoring! \n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Tensor name \"vgg_1/conv3_3/weights\" not found in checkpoint files checkpoint/LiveFaceXL.ckpt\n\t [[Node: save_2/restore_slice_62 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_2/Const_0, save_2/restore_slice_62/tensor_name, save_2/restore_slice_62/shape_and_slice)]]\n\t [[Node: save_2/restore_slice_76/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_save_2/restore_slice_76\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_2/restore_slice_62', defined at:\n  File \"/home/makehave/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/makehave/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-1a897d020642>\", line 57, in <module>\n    saver = tf.train.Saver()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 986, in __init__\n    self.build()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1015, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 620, in build\n    restore_sequentially, reshape)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 357, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 270, in restore_op\n    preferred_shard=preferred_shard))\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/io_ops.py\", line 204, in _restore_slice\n    preferred_shard, name=name)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 359, in _restore_slice\n    preferred_shard=preferred_shard, name=name)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Tensor name \"vgg_1/conv3_3/weights\" not found in checkpoint files checkpoint/LiveFaceXL.ckpt\n\t [[Node: save_2/restore_slice_62 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_2/Const_0, save_2/restore_slice_62/tensor_name, save_2/restore_slice_62/shape_and_slice)]]\n\t [[Node: save_2/restore_slice_76/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_save_2/restore_slice_76\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/makehave/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    462\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    464\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Tensor name \"vgg_1/conv3_3/weights\" not found in checkpoint files checkpoint/LiveFaceXL.ckpt\n\t [[Node: save_2/restore_slice_62 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_2/Const_0, save_2/restore_slice_62/tensor_name, save_2/restore_slice_62/shape_and_slice)]]\n\t [[Node: save_2/restore_slice_76/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_save_2/restore_slice_76\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1a897d020642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found saved model %s, restoring! '\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0msaved_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not found saved model %s. Trainning! '\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0msaved_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1345\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Tensor name \"vgg_1/conv3_3/weights\" not found in checkpoint files checkpoint/LiveFaceXL.ckpt\n\t [[Node: save_2/restore_slice_62 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_2/Const_0, save_2/restore_slice_62/tensor_name, save_2/restore_slice_62/shape_and_slice)]]\n\t [[Node: save_2/restore_slice_76/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_save_2/restore_slice_76\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'save_2/restore_slice_62', defined at:\n  File \"/home/makehave/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/makehave/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-1a897d020642>\", line 57, in <module>\n    saver = tf.train.Saver()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 986, in __init__\n    self.build()\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1015, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 620, in build\n    restore_sequentially, reshape)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 357, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 270, in restore_op\n    preferred_shard=preferred_shard))\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/io_ops.py\", line 204, in _restore_slice\n    preferred_shard, name=name)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 359, in _restore_slice\n    preferred_shard=preferred_shard, name=name)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/makehave/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Tensor name \"vgg_1/conv3_3/weights\" not found in checkpoint files checkpoint/LiveFaceXL.ckpt\n\t [[Node: save_2/restore_slice_62 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_2/Const_0, save_2/restore_slice_62/tensor_name, save_2/restore_slice_62/shape_and_slice)]]\n\t [[Node: save_2/restore_slice_76/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_152_save_2/restore_slice_76\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "tracker = TrackerContour()\n",
    "inputProducer.roi_params['roi_scale'] = 2.5\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback(\"image\", click_and_crop)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saved_ckpt = os.path.join('checkpoint', FLAGS.model_name.split('_')[-1]+'.ckpt')\n",
    "if os.path.exists(saved_ckpt):\n",
    "    print('Found saved model %s, restoring! '%saved_ckpt)\n",
    "    saver.restore(sess, saved_ckpt)\n",
    "    TrackReady = True\n",
    "else: \n",
    "    TrackReady = False\n",
    "    \n",
    "PosReady = False\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, image = cap.read()\n",
    "\n",
    "    # load the image, clone it, and setup the mouse callback function\n",
    "    clone = image.copy()\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # keep looping until the 'q' key is pressed\n",
    "\n",
    "    \n",
    "\n",
    "    # if there are two reference points, then crop the region of interest\n",
    "    # from teh image and display it\n",
    "    if len(refPt) == 2 and key==ord(\"c\"):      \n",
    "        roi = clone[refPt[0][1]:refPt[1][1], refPt[0][0]:refPt[1][0]]\n",
    "        cv2.imshow(\"CroppedROI\", roi)\n",
    "\n",
    "        gt = refPt_2_gt(refPt)\n",
    "        img = image\n",
    "        print(gt, 'gt in first!')\n",
    "        \n",
    "        inputProducer.save_fist_roi_mean(img, gt)\n",
    "\n",
    "\n",
    "    # train\n",
    "    \n",
    "    if key == ord('t') and not TrackReady:\n",
    "        roi_t0, _, rz_factor = inputProducer.extract_roi(img, gt)\n",
    "        \n",
    "        # Predicts the first img.\n",
    "        sess, vgg = init_vgg(roi_t0)\n",
    "        fd = {vgg.imgs: [roi_t0]}\n",
    "        gt_M = inputProducer.gen_mask((28,28)) # rank2 array\n",
    "\n",
    "\n",
    "        ## At t=0. Train S and G Nets \n",
    "        # Instainate SGNets with conv tensors and training.\n",
    "        # 1. feature maps selection\n",
    "        # 2. Train G and S networks.\n",
    "        idx_c4 = select_fms(sess, vgg.conv4_3_norm, gt, rz_factor, fd, FLAGS.sel_num)\n",
    "        idx_c5 = select_fms(sess, vgg.conv5_3_norm, gt, rz_factor, fd, FLAGS.sel_num)\n",
    "        snet = SNet('SNet', FLAGS.sel_num)\n",
    "        gnet = GNet('GNet', FLAGS.sel_num)\n",
    "        train_SGNets(sess, img, gt, vgg, snet, gnet, inputProducer, idx_c4, idx_c5)\n",
    "        saver.save(sess, saved_ckpt)\n",
    "        \n",
    "        TrackReady = True\n",
    "    \n",
    "    \n",
    "    # Records the first position\n",
    "    if key == ord('s'):\n",
    "        gt_last = refPt_2_gt(refPt)\n",
    "        print(gt_last, 'gt in start~!')\n",
    "        PosReady = True\n",
    "        \n",
    "    # Start tracking\n",
    "    if PosReady and TrackReady:\n",
    "        img = image.copy()\n",
    "        #img = inputProducer.Ajust_brighteness(img, gt_last)\n",
    "        roi, _, rz_factor = inputProducer.extract_roi(img, gt_last)\n",
    "\n",
    "        # @inputproducer, remove low level pixel\n",
    "        noise_value = 10#np.argmax(hist)*0.1\n",
    "        roi[roi<noise_value] = roi.mean()\n",
    "        \n",
    "        ## Perform Target localiation predicted by GNet\n",
    "        # Get heat map predicted by GNet\n",
    "        c4_maps, c5_maps = gen_sel_maps(sess, roi, vgg, idx_c4, idx_c5)\n",
    "        fd = {gnet.input_maps: c5_maps, snet.input_maps: c4_maps}\n",
    "        pre_M_g, pre_M_s = sess.run([gnet.pre_M, snet.pre_M], feed_dict=fd)\n",
    "\n",
    "        pre_M = tracker.preporcess_heatmaps(pre_M_g, pre_M_s, resize=(224,224))\n",
    "        pre_loc = tracker.predict_location(pre_M,gt_last,rz_factor,threshold=np.arange(0.3, 0.9, 0.05))\n",
    "        \n",
    "        gt_last = pre_loc\n",
    "        x,y,w,h = pre_loc\n",
    "        print('pre_loc', pre_loc)\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(225,0,0),2)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(image, 'conf score: %s'%1,(5,20), font, 0.6,(255,0,0),1,cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow(\"pre_M_g\", pre_M_g)\n",
    "        cv2.imshow(\"pre_M_s\", pre_M_s)\n",
    "        cv2.imshow(\"pre_M_g\", pre_M_g)\n",
    "        cv2.imshow(\"ROI\", roi)\n",
    "        # Finetune SNet\n",
    "        \n",
    "        print('Tracking done in step: %s'%tracker.step)\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"image\", image)\n",
    "\n",
    "# close all open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"pre_M\", pre_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refPt_2_gt(refPt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
