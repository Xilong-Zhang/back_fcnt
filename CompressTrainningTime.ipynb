{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/makehave/anaconda3/bin/../lib/libgomp.so.1: version `GOMP_4.0' not found (required by /usr/lib/x86_64-linux-gnu/libsoxr.so.0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9bdf28d42bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import custom class and functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0minputproducer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputProducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrackerVanilla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvgg16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVgg16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msgnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/makehave/xlrepo/back_fcnt/tracker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/makehave/anaconda3/bin/../lib/libgomp.so.1: version `GOMP_4.0' not found (required by /usr/lib/x86_64-linux-gnu/libsoxr.so.0)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main script for FCNT tracker. \n",
    "\"\"\"\n",
    "\n",
    "# Import custom class and functions\n",
    "from inputproducer import InputProducer\n",
    "from tracker import TrackerVanilla\n",
    "from vgg16 import Vgg16\n",
    "from sgnet import GNet, SNet\n",
    "from utils import img_with_bbox, IOU_eval, select_fms\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from scipy.misc import imresize\n",
    "from subprocess import call\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "tf.app.flags.DEFINE_integer('iter_epoch_sg', 5,\n",
    "                          \"\"\"Number of epoches for trainning\"\"\"\n",
    "                          \"\"\"SGnet works\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size', 35,\n",
    "                          \"\"\"Batch size for SGNet trainning\"\"\"\n",
    "                          \"\"\"SGnet works\"\"\")\n",
    "tf.app.flags.DEFINE_integer('n_samples_per_batch', 5000,\n",
    "                          \"\"\"Number of samples per batch for trainning\"\"\"\n",
    "                          \"\"\"SGnet works\"\"\")\n",
    "tf.app.flags.DEFINE_integer('iter_max', 1349,\n",
    "\t\t\t\t\t\t\t\"\"\"Max iter times through imgs\"\"\")\n",
    "tf.app.flags.DEFINE_integer('sel_num', 354,\n",
    "                          \"\"\"Number of feature maps selected.\"\"\")\n",
    "tf.app.flags.DEFINE_string('model_name', 'contour_Suv',\\\n",
    "\t\t\t\t\t\t\"\"\"true for train, false for eval\"\"\")\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "## Define varies pathes\n",
    "DATA_ROOT = 'data/Suv'\n",
    "PRE_ROOT = os.path.join(DATA_ROOT, 'img_loc')\n",
    "IMG_PATH = os.path.join(DATA_ROOT, 'img')\n",
    "GT_PATH = os.path.join(DATA_ROOT, 'groundtruth_rect.txt')\n",
    "VGG_WEIGHTS_PATH = 'vgg16_weights.npz'\n",
    "\n",
    "if not os.path.isdir(PRE_ROOT):\n",
    "    os.mkdir(PRE_ROOT)\n",
    "\n",
    "\n",
    "TB_SUMMARY = os.path.join('tb_summary', FLAGS.model_name)\n",
    "if not os.path.isdir('tb_summary'):\n",
    "    os.mkdir('tb_summary')\n",
    "if not os.path.isdir(TB_SUMMARY):\n",
    "    os.mkdir(TB_SUMMARY)\n",
    "\n",
    "CKPT_PATH = 'checkpoint'\n",
    "if not os.path.isdir(CKPT_PATH):\n",
    "    os.mkdir(CKPT_PATH)\n",
    "\n",
    "model_name = FLAGS.model_name+'.ckpt'\n",
    "CKPT_MODEL = os.path.join(CKPT_PATH, model_name)\n",
    "\n",
    "\n",
    "def init_vgg(roi_t0, predict=False):\n",
    "    \"\"\"\n",
    "    Initialize a tf.Session and a vgg16 graph. Followed\n",
    "    by forwarding the vgg net once to predict top5 class labels\n",
    "    for image generated in the first frame.\n",
    "\n",
    "    Args:\n",
    "        roi_t0: np.ndarray with shape (28x28x3), extracted roi in the first frame.\n",
    "    Returns:\n",
    "        sess: tf.Session object.\n",
    "        vgg: Vgg16 class instance.\n",
    "    \"\"\"\n",
    "    print('Classify it with a pre-trained Vgg16 model.')\n",
    "    t_start = time.time()\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    vgg = Vgg16(VGG_WEIGHTS_PATH, sess)\n",
    "    if predict:\n",
    "        vgg.print_prob(roi_t0, sess)\n",
    "    print('Forwarding the vgg net cost : %.2f s'%(time.time() - t_start))\n",
    "    return sess, vgg\n",
    "\n",
    "def gen_sel_maps(sess, roi, vgg, idx_c4, idx_c5):\n",
    "    \"\"\"Returns selected c4 and c5 maps\"\"\"\n",
    "    if len(roi.shape) == 3: roi = [roi]\n",
    "    fd = {vgg.imgs : roi}\n",
    "    c4_arr, c5_arr = sess.run([vgg.conv4_3_norm, vgg.conv5_3_norm], feed_dict=fd)\n",
    "    c4_maps = c4_arr[...,idx_c4]\n",
    "    c5_maps = c5_arr[...,idx_c5]\n",
    "    return c4_maps, c5_maps\n",
    "\n",
    "\n",
    "def train_SGNets(sess, img, gt, vgg, snet, gnet, inputProducer, idx_c4, idx_c5):\n",
    "    \"\"\"\n",
    "    Train SGnets' variables by minimizing a composite L2 regression losses.\n",
    "\n",
    "    Args:\n",
    "        sess: tf.Session object.\n",
    "        vgg: Vgg16 class instance.\n",
    "        snet: SNet class instance.\n",
    "        gnet:  GNet class instance.\n",
    "        inputProducer: InputProducer class instance.\n",
    "    \"\"\"\n",
    "    gnet.params['wd'] = 0.5\n",
    "    gloss, sloss = gnet.loss(), snet.loss()\n",
    "    loss = gloss  + sloss\n",
    "    tf.scalar_summary('loss', loss)\n",
    "    writer = tf.train.SummaryWriter(TB_SUMMARY, sess.graph)\n",
    "    \n",
    "    vars_train = gnet.variables + snet.variables\n",
    "\n",
    "    # Backprop using SGD and updates vgg variables and sgnets variables\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    lr_exp = tf.train.exponential_decay(\n",
    "            0.25, # Initial learning rate \n",
    "            global_step, \n",
    "            1000, # Decay steps \n",
    "            0.8, # Decay rate \n",
    "            name='sg_lr')\n",
    "\n",
    "    tf.scalar_summary('Learning rate', lr_exp)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr_exp)\n",
    "    train_op = optimizer.minimize(loss, var_list= vars_train, global_step=global_step)\n",
    "    merged = tf.merge_all_summaries()\n",
    "\n",
    "    sample_batches, target_batches = inputProducer.gen_batches(img, gt, n_samples=FLAGS.n_samples_per_batch, batch_sz=FLAGS.batch_size, pos_ratio=0.5, scale_factors=np.arange(0.5, 5., 0.2)) #np.array([1]))#\n",
    "    print('Start training the SGNets........ for %s epoches'%FLAGS.iter_epoch_sg)\n",
    "    saver = tf.train.Saver()\n",
    "    step = 1\n",
    "    loss_list = []\n",
    "    for ep in range(FLAGS.iter_epoch_sg):\n",
    "        print('Total batches in each epoch: ', len(sample_batches))\n",
    "        for roi, target in zip(sample_batches, target_batches):\n",
    "            #roi[roi>0] = 1 # neglect gaussian..set to 1 for target arear\n",
    "            \n",
    "            t = time.time()\n",
    "            c4_maps, c5_maps = gen_sel_maps(sess, roi, vgg, idx_c4, idx_c5)\n",
    "            \n",
    "            fd = {gnet.input_maps: c5_maps, gnet.gt_M: target, \n",
    "                  snet.input_maps: c4_maps, snet.gt_M: target}\n",
    "            \n",
    "            # Initialization \n",
    "            if step == 1:\n",
    "                loss_g = 10\n",
    "                init_s = 0\n",
    "                while loss_g > 1.5:\n",
    "                    init_s += 1\n",
    "                    sess.run(tf.initialize_variables(gnet.variables))\n",
    "                    loss_g = sess.run(gloss, feed_dict=fd)\n",
    "                    print('Initial Gnet Loss: ', loss_g, 'In steps: ', init_s)\n",
    "                sess.run(tf.initialize_variables(snet.variables + [global_step]))\n",
    "                \n",
    "            \n",
    "            pre_M_g, l, _, lr = sess.run([gnet.pre_M, loss, train_op, lr_exp], feed_dict=fd)\n",
    "            \n",
    "            loss_list += [l]\n",
    "            if l <= 0.1:\n",
    "                print('break learning!')\n",
    "                break\n",
    "            if step % 20 == 0:\n",
    "                \n",
    "                loss_ac = np.diff(np.diff(loss_list[-19:]))\n",
    "                loss_ac_summary = tf.scalar_summary('Loss acceleration', loss_ac.mean())\n",
    "                \n",
    "                \n",
    "                summary_img_g = tf.image_summary('pre_M', \n",
    "                                                 np.repeat(pre_M_g[...,np.newaxis], 3, axis=-1), name='GMap')\n",
    "\n",
    "                summary, img_summary_g, ac_loss_summary = sess.run([merged, summary_img_g, loss_ac_summary], feed_dict=fd)\n",
    "\n",
    "                writer.add_summary(summary, global_step=step)\n",
    "                writer.add_summary(img_summary_g, global_step=step)\n",
    "                writer.add_summary(ac_loss_summary, global_step=step)\n",
    "                \n",
    "                loss_std = np.std(loss_list[-19:])\n",
    "                if loss_std <= 0.007:\n",
    "                    \n",
    "                    print('Stop learning! Last 10 batches Loss Std: ', loss_std)\n",
    "                    break\n",
    "\n",
    "            #if step % 20 == 0:\n",
    "                print('Epoch: ', ep+1, 'Step: ', (ep+1)*step, 'Loss : %.2f'%l, \\\n",
    "                    'Speed: %.2f second/batch'%(time.time()-t), 'Lr: ', lr)\n",
    "                #saver.save(sess, CKPT_MODEL)\n",
    "            step += 1\n",
    "\n",
    "\n",
    "\n",
    "print('Reading the first image...')\n",
    "t_start = time.time()\n",
    "## Instantiate inputProducer and retrive the first img\n",
    "# with associated ground truth. \n",
    "inputProducer = InputProducer(IMG_PATH, GT_PATH)\n",
    "img, gt, s  = next(inputProducer.gen_img)\n",
    "roi_t0, _, rz_factor = inputProducer.extract_roi(img, gt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predicts the first img.\n",
    "sess, vgg = init_vgg(roi_t0)\n",
    "fd = {vgg.imgs: [roi_t0]}\n",
    "gt_M = inputProducer.gen_mask((28,28)) # rank2 array\n",
    "\n",
    "\n",
    "## At t=0. Train S and G Nets \n",
    "# Instainate SGNets with conv tensors and training.\n",
    "# 1. feature maps selection\n",
    "# 2. Train G and S networks.\n",
    "idx_c4 = select_fms(sess, vgg.conv4_3_norm, gt, rz_factor, fd, FLAGS.sel_num)\n",
    "idx_c5 = select_fms(sess, vgg.conv5_3_norm, gt, rz_factor, fd, FLAGS.sel_num)\n",
    "snet = SNet('SNet', FLAGS.sel_num)\n",
    "gnet = GNet('GNet', FLAGS.sel_num)\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saved_ckpt = os.path.join('checkpoint', FLAGS.model_name.split('_')[-1]+'.ckpt')\n",
    "if os.path.exists(saved_ckpt):\n",
    "    print('Found saved model %s, restoring! '%saved_ckpt)\n",
    "    saver.restore(sess, saved_ckpt)\n",
    "else:\n",
    "    print('Not found saved model %s. Trainning! '%saved_ckpt)\n",
    "    train_SGNets(sess, img, gt, vgg, snet, gnet, inputProducer, idx_c4, idx_c5)\n",
    "    saver.save(sess, saved_ckpt)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "show = skimage.io.imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "inputProducer = InputProducer(IMG_PATH, GT_PATH)\n",
    "img, gt, s  = next(inputProducer.gen_img)\n",
    "roi_t0, _, rz_factor = inputProducer.extract_roi(img, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputProducer.roi_params['roi_scale'] = 1#0.0723 * 35\n",
    "roi, _, rz_factor = inputProducer.extract_roi(img, gt)\n",
    "print(gt)\n",
    "show(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(66*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "inputProducer = InputProducer(IMG_PATH, GT_PATH)\n",
    "img, gt, s  = next(inputProducer.gen_img)\n",
    "\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img.astype(float).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y,w,h = gt\n",
    "roi_mean = img[y:y+h, x:x+w].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(arear.max(), arear.min(), arear.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roi_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roi_cur_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ones([h, w], dtype=np.uint8)*int(roi_mean-roi_cur_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y,w,h = gt_last\n",
    "roi_cur_mean = img[y:y+h, x:x+w].mean()\n",
    "img[y:y+h, x:x+w] += int(roi_cur_mean- roi_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1.5/factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 255\n",
    "(i>250 and i <260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Instainate a tracker object, set apoproaite initial parameters.\n",
    "tracker = TrackerContour()\n",
    "inputProducer.roi_params['roi_scale'] = 2.5\n",
    "\n",
    "print(\"Total time cost for initialization : %.2f s\"%(time.time() - t_start))\n",
    "\n",
    "# Iter imgs\n",
    "inputProducer = InputProducer(IMG_PATH, GT_PATH)\n",
    "img, gt, s  = next(inputProducer.gen_img)\n",
    "x,y,w,h = gt\n",
    "roi_mean = img[y:y+h, x:x+w].mean()\n",
    "\n",
    "gt_last = gt\n",
    "\n",
    "gt_list = []\n",
    "pre_M_list = []\n",
    "roi_list = []\n",
    "res_list = []\n",
    "diff_list = []\n",
    "\n",
    "def dis2center(loc, sh=112):\n",
    "    x,y,w,h = loc\n",
    "    f1 = ((x-112)**2+(y-112)**2)**0.5\n",
    "    f2 = ((x+w-112)**2+(y+w-112)**2)**0.5\n",
    "    return f1, f2\n",
    "\n",
    "def compute_score(loc_list, last_pre_loc, arear_list):\n",
    "    scores_dis = []\n",
    "    x0, y0, w0, h0 = last_pre_loc\n",
    "    for loc in loc_list:\n",
    "        x, y, w, h = loc\n",
    "        #scores += [((x-x0)**2+ (y-y0)**2+ (w-w0)**2+ (h-h0)**2)**0.5]\n",
    "        scores_dis += [abs(x-x0)+ abs(y-y0)+ abs(w-w0)+ abs(h-h0)]\n",
    "    scores_dis = np.array(scores_dis) / max(scores_dis)\n",
    "    arear_list = np.array(arear_list)/ max(arear_list)\n",
    "    scores = scores_dis / arear_list\n",
    "    best_idx = np.argmin(scores)\n",
    "    return loc_list[best_idx], best_idx, scores[best_idx]\n",
    "\n",
    "def compute_score1(loc_list, f1_0, f2_0):\n",
    "    scores = []\n",
    "    for loc in loc_list:\n",
    "        f1, f2 = dis2center(loc)\n",
    "        scores += [(f1-f1_0)**2+(f2-f2_0)**2]\n",
    "    best_idx = np.argmin(scores)\n",
    "    return loc_list[best_idx]\n",
    "\n",
    "\n",
    "conf_scores = []\n",
    "total_arear = 224**2\n",
    "arear_in_bbox = []\n",
    "for i in range(len(inputProducer.imgs_path_list)-1):\n",
    "\n",
    "\n",
    "    t_enter = time.time()\n",
    "    # Gnerates next frame infos\n",
    "    img, gt_cur, s  = next(inputProducer.gen_img)\n",
    "    \n",
    "    # brighten img @inputProducer\n",
    "    img = img.astype(np.float)\n",
    "    x,y,w,h = gt_last\n",
    "    roi_cur_mean = img[y:y+h, x:x+w].mean()\n",
    "    img[y:y+h, x:x+w] += np.ones([h, w, 3])*int(roi_mean-roi_cur_mean)\n",
    "    img[img>255] = 255\n",
    "    \n",
    "    if i%10==0:\n",
    "        show(img)\n",
    "        plt.show()\n",
    "    \n",
    "    #print(gt_last)\n",
    "    ## Crop a rectangle ROI region centered at last target location.\n",
    "    roi, _, rz_factor = inputProducer.extract_roi(img, gt_last)\n",
    "    roi_list += [roi]\n",
    "    \n",
    "    \n",
    "    # @inputproducer, remove low level pixel\n",
    "    noise_value = 10#np.argmax(hist)*0.1\n",
    "    roi[roi<noise_value] = roi.mean()\n",
    "\n",
    "    ## Perform Target localiation predicted by GNet\n",
    "    # Get heat map predicted by GNet\n",
    "    c4_maps, c5_maps = gen_sel_maps(sess, roi, vgg, idx_c4, idx_c5)\n",
    "    fd = {gnet.input_maps: c5_maps, snet.input_maps: c4_maps}\n",
    "\n",
    "    pre_M_g, pre_M_s = sess.run([gnet.pre_M, snet.pre_M], feed_dict=fd)\n",
    "    pre_M_list += [(pre_M_g.copy(), pre_M_s.copy())]\n",
    "    \n",
    "    \n",
    "    pre_M = tracker.preporcess_heatmaps(pre_M_g, pre_M_s, resize=(224,224))\n",
    "    \n",
    "    tracker.predict_first_frame(pre_M_g, threshold=0.7)\n",
    "        \n",
    "    \n",
    "    if i == 0:\n",
    "        pre_M[pre_M<(0.7)] = 0\n",
    "        \n",
    "        cvuint8 = cv2.convertScaleAbs(pre_M)\n",
    "        img2, contours, hierarchy = cv2.findContours(cvuint8, 1, 2)\n",
    "\n",
    "        assert len(contours)>=1\n",
    "\n",
    "        arear_list, bbox_list, COM_list = [], [], []\n",
    "        for cnt in contours:\n",
    "\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            bbox_list += [(x,y,w,h)]\n",
    "            arear_list += [cv2.contourArea(cnt)]\n",
    "\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            COM_list += [(cx, cy)]\n",
    "        best_idx = np.argmax(arear_list)\n",
    "        pre_loc_roi = bbox_list[best_idx]\n",
    "        com = COM_list[best_idx]\n",
    "        last_arear = arear_list[best_idx]\n",
    "        last_pre_loc_roi = pre_loc_roi\n",
    "        conf_score = 1\n",
    "        show(pre_M)\n",
    "        plt.show()\n",
    "    else:\n",
    "\n",
    "        arear_list, bbox_list, COM_list, displace_list = [], [], [], []\n",
    "        for shrehold in np.arange(0.3, 0.9, 0.05):\n",
    "            pre_M = pre_M_g.copy()\n",
    "            pre_M[pre_M<shrehold] = 0\n",
    "            #show(pre_M)\n",
    "            #plt.show()\n",
    "            cvuint8 = cv2.convertScaleAbs(pre_M)\n",
    "            img2, contours, hierarchy = cv2.findContours(cvuint8, 1, 2)\n",
    "            if len(contours) < 1: continue\n",
    "\n",
    "            for cnt in contours:\n",
    "                try:\n",
    "                    M = cv2.moments(cnt)\n",
    "                    cx = int(M['m10']/M['m00'])\n",
    "                    cy = int(M['m01']/M['m00'])\n",
    "                except ZeroDivisionError:\n",
    "                    continue\n",
    "                COM_list += [(cx, cy)]\n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                if x+w >= 224 or y+h >224: continue\n",
    "                if w/rz_factor>224 or h/rz_factor>224: continue\n",
    "                bbox_list += [(x,y,w,h)]\n",
    "                arear_list += [cv2.contourArea(cnt)]\n",
    "        print('Total boxes: ', len(bbox_list), 'Current scale: ', inputProducer.roi_params['roi_scale'])\n",
    "        inputProducer.roi_params['roi_scale'] = 1.5#(1.5/14) * len(bbox_list)\n",
    "                \n",
    "                #displace = ((cx-hs)**2 + (cy-hs)**2)**0.5\n",
    "                #displace_list += [displace]\n",
    "                #print(shrehold, 'shrehold', [x,y,w,h])\n",
    "\n",
    "        #score_contour = (np.array(arear_list)- last_arear) * np.array(displace_list)\n",
    "        #best_contour_idx = np.argmin(score_contour)\n",
    "        #pre_loc_roi = bbox_list[best_contour_idx]\n",
    "        #last_arear = arear_list[best_contour_idx]\n",
    "        pre_loc_roi, idx, conf_score = compute_score(bbox_list, last_pre_loc_roi, arear_list)\n",
    "        conf_scores += [conf_score]\n",
    "        cx_pre, cy_pre = COM_list[idx]\n",
    "        last_pre_loc_roi = pre_loc_roi\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        #break\n",
    "    ########\n",
    "    \n",
    "    if i % 10 ==0 or (i>250 and i <260):\n",
    "        print('step: ', i)\n",
    "        x,y,w,h = pre_loc_roi\n",
    "        plt.figure(figsize=(10, 10)) \n",
    "        cv2.rectangle(pre_M_g,(x,y),(x+w,y+h),(1),2)\n",
    "        plt.subplot(1,3,1), show(pre_M_g)\n",
    "        plt.subplot(1,3,2), show(pre_M_s)\n",
    "        plt.subplot(1,3,3), show(roi)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        plt.plot(hist)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    #smoth_num = \n",
    "    if len(arear_in_bbox) > 50:\n",
    "        #avg_arear = sum(arear_in_bbox[-15:])/15\n",
    "        #roi_scale_coeff = (avg_arear/total_arear)*35\n",
    "        #if roi_scale_coeff < 1: roi_scale_coeff = 0\n",
    "        st, s0 = sum(arear_in_bbox[-50:-20])/30, sum(arear_in_bbox[-20:])/20\n",
    "        try:\n",
    "            factor = st-s0\n",
    "        except ZeroDivisionError:\n",
    "            factor = 1\n",
    "        \n",
    "        \n",
    "        roi_scale_coeff = 1.5 # 0.001707333520651869* factor #- 0.004214667 * (factor) + 1.5\n",
    "        inputProducer.roi_params['roi_scale'] = roi_scale_coeff\n",
    "        print(roi_scale_coeff, arear_in_bbox[-30], arear_in_bbox[-1], factor, '$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "        #print('scale: ', inputProducer.roi_params['roi_scale'])\n",
    "        #show(roi)\n",
    "        #plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    print(pre_loc, 'best loc roi', gt_cur)\n",
    "    \n",
    "    diff = np.array(pre_loc) - np.array(gt_cur)\n",
    "    if sum([abs(i) for i in diff]) > 50:\n",
    "        diff_list += [i-1]\n",
    "    #print('Step: ',i-1, 'pre - actual : ', diff, 'Conf level:', tracker.cur_best_conf)\n",
    "\n",
    "\n",
    "    # Draw bbox on image. And print associated IoU score.\n",
    "    x,y,w,h = [int(i) for i in pre_loc]\n",
    "    xt, yt, wt, ht = gt_cur\n",
    "    xl, yl, wl, hl = [int(i) for i in gt_last]\n",
    "    imgcopy = img.copy().astype(np.uint8)\n",
    "    if i!=0: imgcopy[cx_pre,cy_pre, 0] = 225\n",
    "    cv2.rectangle(imgcopy,(x,y),(x+w,y+h),(225,0,0),2)\n",
    "    cv2.rectangle(imgcopy,(xt,yt),(xt+wt,yt+ht),(0,225,0),1)\n",
    "\n",
    "    #cv2.rectangle(imgcopy,(cx_pre-1,cy_pre-1),(cx_pre+1,cy_pre+1),(0,225,0),1)\n",
    "    cv2.putText(imgcopy, 'conf score: %s'%conf_score,(5,20), font, 0.6,(255,0,0),1,cv2.LINE_AA)\n",
    "\n",
    "    file_name = FLAGS.model_name + inputProducer.imgs_path_list[i-1].split('/')[-1]\n",
    "    file_name = os.path.join(PRE_ROOT, file_name)\n",
    "    \n",
    "    x,y,w,h = pre_loc_roi\n",
    "    test = cv2.rectangle(roi,(x,y),(x+w,y+h),(225,0,0),1)\n",
    "    plt.imsave(file_name, imgcopy)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "\n",
    "\n",
    "    #show(imgcopy)\n",
    "    #plt.show()\n",
    "\n",
    "    res_list += [imgcopy]\n",
    "\n",
    "    gt_last = pre_loc\n",
    "    gt_list += [pre_loc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "- 0.004214667 * (factor) + 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1.5/factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-0.004214667041303738 * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int(roi_mean-roi_cur_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.ones([h, w, 3])*int(roi_mean-roi_cur_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist = np.bincount(roi.ravel(),minlength=256)\n",
    "\n",
    "plt.plot(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = np.bincount(roi.ravel(),minlength=256)\n",
    "\n",
    "plt.plot(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "vid_path_prefix = os.path.join(PRE_ROOT, FLAGS.model_name) \n",
    "os.system('ffmpeg -framerate 25 -i %s%%04d.jpg -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p %s.mp4'\\\n",
    "          %(vid_path_prefix, FLAGS.model_name+'trail5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "show(imgcopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgcopy[cy_pre, cx_pre]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try opencv adpaptie threlhoding and contouring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1), show(pre_M_g)\n",
    "plt.subplot(1,2,2), show(pre_M_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=411\n",
    "show(res_list[k])\n",
    "plt.show()\n",
    "show(roi_list[k])\n",
    "plt.show()\n",
    "gm, sm = pre_M_list[k]\n",
    "show(pre_M_list[k][0])\n",
    "plt.show()\n",
    "show(pre_M_list[k][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gm1 = gm.copy()\n",
    "gm1[gm1<0.75]=0\n",
    "show(gm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvuint8 = cv2.convertScaleAbs(gm1)\n",
    "img2, contours, hierarchy = cv2.findContours(cvuint8, 1, 2)\n",
    "\n",
    "assert len(contours)>=1\n",
    "\n",
    "arear_list, bbox_list, COM_list = [], [], []\n",
    "for cnt in contours:\n",
    "    \n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    bbox_list += [(x,y,w,h)]\n",
    "    arear_list += [cv2.contourArea(cnt)]\n",
    "    \n",
    "    M = cv2.moments(cnt)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    COM_list += [(cx, cy)]\n",
    "best_idx = np.argmax(arear_list)\n",
    "largest_contour = bbox_list[best_idx]\n",
    "com = COM_list[best_idx]\n",
    "print(largest_contour)\n",
    "print(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y,w,h = largest_contour\n",
    "gm2 = cv2.rectangle(gm1,(x,y),(x+w,y+h),(1),1)\n",
    "show(gm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbox_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#img = cv2.imread('star.jpg',0)\n",
    "ret,thresh = cv2.threshold(gm,127,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gm = gm*225\n",
    "gm = gm.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(gm, cv2.COLOR_BGR2GRAY)\n",
    "cvuint8 = cv2.convertScaleAbs(gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2, contours, hierarchy = cv2.findContours(cvuint8, 1, 2)\n",
    "\n",
    "cnt = contours[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "img = cv2.rectangle(gm,(x,y),(x+w,y+h),(0,255,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vid_path_prefix = os.path.join(PRE_ROOT, FLAGS.model_name) \n",
    "os.system('ffmpeg -framerate 25 -i %s%%04d.jpg -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p %s.mp4'\\\n",
    "          %(vid_path_prefix, FLAGS.model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(inputProducer.imgs_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,prem in enumerate(pre_M_list):\n",
    "    if k % 20 ==0:\n",
    "        show(prem)\n",
    "        plt.show()\n",
    "        show(roi_list[k])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "t_enter = time.time()\n",
    "# Gnerates next frame infos\n",
    "img, gt_cur, s  = next(inputProducer.gen_img)\n",
    "\n",
    "## Crop a rectangle ROI region centered at last target location.\n",
    "roi, _, rz_factor = inputProducer.extract_roi(img, gt_last)\n",
    "\n",
    "## Perform Target localiation predicted by GNet\n",
    "# Get heat map predicted by GNet\n",
    "c4_maps, c5_maps = gen_sel_maps(sess, roi, vgg, idx_c4, idx_c5)\n",
    "fd = {gnet.input_maps: c5_maps, snet.input_maps: c4_maps}\n",
    "\n",
    "pre_M_g, _ = sess.run([gnet.pre_M, snet.pre_M], feed_dict=fd)\n",
    "\n",
    "#pre_M_g = imresize(pre_M_g, (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.system('ffmpeg -framerate 25 -i %s%%04d.jpg -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p %sTEST.mp4'%(vid_path_prefix, FLAGS.model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "call(['ffmpeg', '-framerate 25 -i %s%%04d.jpg -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p %sTEST.mp4'%(vid_path_prefix, FLAGS.model_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(pre_M_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_M_g =  imresize(pre_M_g, (224,224))\n",
    "# Localize target with monte carlo sampling.\n",
    "pre_loc = tracker.predict_location(pre_M_g, gt_last, rz_factor, img)\n",
    "\n",
    "gt_last = pre_loc\n",
    "gt_list += [pre_loc]\n",
    "print('pre: ', pre_loc, 'actual: ', gt_cur)\n",
    "\n",
    "# Draw bbox on image. And print associated IoU score.\n",
    "img_bbox = img_with_bbox(img, pre_loc,c=1)\n",
    "show(img_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(img_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_M_g_1 = pre_M_g.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_M_g_1[pre_M_g_1<0.5] = 0\n",
    "show(pre_M_g_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argmax(pre_M_g_1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
